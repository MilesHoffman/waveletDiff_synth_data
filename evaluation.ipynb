{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro_md",
            "metadata": {},
            "source": [
                "# WaveletDiff Evaluation (Refactored)\n",
                "\n",
                "This notebook evaluates a trained WaveletDiff model. It acts as a frontend interface, delegating heavy logic to `src/evaluation` modules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 1: Global Configuration\n",
                "import os\n",
                "\n",
                "# --- Drive Paths ---\n",
                "DRIVE_MOUNT_PATH = \"/content/drive\" # @param {type:\"string\"}\n",
                "DRIVE_BASE_PATH = \"/content/drive/MyDrive/personal_drive/trading/waveletDiff\" # @param {type:\"string\"}\n",
                "CHECKPOINT_FOLDER = \"checkpoints\" # @param {type:\"string\"}\n",
                "SAMPLES_FOLDER = \"samples\" # @param {type:\"string\"}\n",
                "\n",
                "MODEL_FILENAME = \"stocks_experiment.tar.gz\" # @param {type:\"string\"}\n",
                "MODEL_BASENAME = MODEL_FILENAME.replace('.tar.gz', '').replace('.zip', '').replace('.ckpt', '').replace('.tgz', '').replace('.gz', '')\n",
                "\n",
                "DRIVE_CHECKPOINT_PATH = os.path.join(DRIVE_BASE_PATH, CHECKPOINT_FOLDER, MODEL_FILENAME)\n",
                "DRIVE_SAMPLES_PATH = os.path.join(DRIVE_BASE_PATH, SAMPLES_FOLDER, MODEL_BASENAME)\n",
                "\n",
                "# --- Repository Settings ---\n",
                "REPO_BRANCH = \"develop\" # @param {type:\"string\"}\n",
                "\n",
                "# --- Evaluation Settings ---\n",
                "DATASET = \"stocks\" # @param {type:\"string\"}\n",
                "EXPERIMENT_NAME = \"evaluation_run\" # @param {type:\"string\"}\n",
                "NUM_SAMPLES = 2000 # @param {type:\"integer\"}\n",
                "SAMPLING_METHOD = \"ddpm\" # @param [\"ddpm\", \"ddim\"]\n",
                "COMPILE_MODE = \"none\" # @param [\"none\", \"default\", \"reduce-overhead\", \"max-autotune\"]\n",
                "DEVICE = \"cuda\" # @param [\"cuda\", \"cpu\"]\n",
                "\n",
                "# --- Evaluation Options ---\n",
                "EXCLUDE_VOLUME = True # @param {type:\"boolean\"}\n",
                "CACHE_SAMPLES_TO_DRIVE = True # @param {type:\"boolean\"}\n",
                "USE_CACHED_SAMPLES = True # @param {type:\"boolean\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 2: Setup (Clone, Install, Mount)\n",
                "import os\n",
                "import sys\n",
                "import shutil\n",
                "from google.colab import drive\n",
                "\n",
                "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
                "REPO_NAME = \"waveletDiff_synth_data\"\n",
                "REPO_PATH = os.path.abspath(REPO_NAME)\n",
                "\n",
                "# 1. Clone or Pull Repo\n",
                "if os.path.exists(REPO_PATH):\n",
                "    nested_path = os.path.join(REPO_PATH, REPO_NAME)\n",
                "    if os.path.exists(nested_path):\n",
                "        shutil.rmtree(REPO_PATH)\n",
                "        !git clone {REPO_URL} {REPO_NAME}\n",
                "        !git -C {REPO_NAME} checkout {REPO_BRANCH}\n",
                "    else:\n",
                "        !git -C {REPO_NAME} fetch origin\n",
                "        !git -C {REPO_NAME} checkout {REPO_BRANCH}\n",
                "        !git -C {REPO_NAME} pull origin {REPO_BRANCH}\n",
                "else:\n",
                "    !git clone {REPO_URL} {REPO_NAME}\n",
                "    !git -C {REPO_NAME} checkout {REPO_BRANCH}\n",
                "\n",
                "# 2. Install Dependencies\n",
                "!pip install -q pytorch-lightning pywavelets scipy pandas tqdm scikit-learn tslearn seaborn statsmodels\n",
                "\n",
                "# 3. Mount Drive & Setup Paths\n",
                "if not os.path.exists(DRIVE_MOUNT_PATH):\n",
                "    drive.mount(DRIVE_MOUNT_PATH)\n",
                "\n",
                "for p in [os.path.join(REPO_PATH, \"src\"), os.path.join(REPO_PATH, \"src\", \"evaluation\")]:\n",
                "    if p not in sys.path: sys.path.append(p)\n",
                "\n",
                "# 4. Prepare Experiments\n",
                "local_exp_dir = os.path.join(REPO_PATH, \"outputs\", EXPERIMENT_NAME)\n",
                "os.makedirs(local_exp_dir, exist_ok=True)\n",
                "\n",
                "if os.path.exists(DRIVE_CHECKPOINT_PATH):\n",
                "    print(f\"Unpacking model from {DRIVE_CHECKPOINT_PATH}...\")\n",
                "    if DRIVE_CHECKPOINT_PATH.endswith(\".ckpt\"):\n",
                "        shutil.copy2(DRIVE_CHECKPOINT_PATH, os.path.join(local_exp_dir, \"checkpoint.ckpt\"))\n",
                "    else:\n",
                "        shutil.unpack_archive(DRIVE_CHECKPOINT_PATH, local_exp_dir, format='gztar' if '.gz' in DRIVE_CHECKPOINT_PATH and not '.tar' in DRIVE_CHECKPOINT_PATH else None)\n",
                "else:\n",
                "    print(f\"❌ Model file not found.\")\n",
                "\n",
                "# Sync configs\n",
                "if os.path.exists(os.path.join(REPO_PATH, \"WaveletDiff_source\", \"configs\")):\n",
                "    shutil.rmtree(os.path.join(REPO_PATH, \"configs\"), ignore_errors=True)\n",
                "    shutil.copytree(os.path.join(REPO_PATH, \"WaveletDiff_source\", \"configs\"), os.path.join(REPO_PATH, \"configs\"))\n",
                "\n",
                "print(\"✅ Setup Complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gen_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 3: Generate or Load Samples\n",
                "import numpy as np\n",
                "os.chdir(os.path.join(REPO_PATH, \"src\"))\n",
                "\n",
                "# Dollar space paths\n",
                "local_gen_path = f\"../outputs/{EXPERIMENT_NAME}/{SAMPLING_METHOD}_samples.npy\"\n",
                "local_real_path = f\"../outputs/{EXPERIMENT_NAME}/real_samples.npy\"\n",
                "drive_gen_path = os.path.join(DRIVE_SAMPLES_PATH, f\"{SAMPLING_METHOD}_samples.npy\")\n",
                "drive_real_path = os.path.join(DRIVE_SAMPLES_PATH, \"real_samples.npy\")\n",
                "\n",
                "# Reparameterized (norm) space paths\n",
                "local_gen_norm_path = f\"../outputs/{EXPERIMENT_NAME}/{SAMPLING_METHOD}_samples_norm.npy\"\n",
                "local_real_norm_path = f\"../outputs/{EXPERIMENT_NAME}/real_samples_norm.npy\"\n",
                "drive_gen_norm_path = os.path.join(DRIVE_SAMPLES_PATH, f\"{SAMPLING_METHOD}_samples_norm.npy\")\n",
                "drive_real_norm_path = os.path.join(DRIVE_SAMPLES_PATH, \"real_samples_norm.npy\")\n",
                "\n",
                "if USE_CACHED_SAMPLES and os.path.exists(drive_gen_path):\n",
                "    print(\"Loading cached samples...\")\n",
                "    os.makedirs(os.path.dirname(local_gen_path), exist_ok=True)\n",
                "    shutil.copy2(drive_gen_path, local_gen_path)\n",
                "    shutil.copy2(drive_real_path, local_real_path)\n",
                "    # Copy norm files if they exist\n",
                "    if os.path.exists(drive_gen_norm_path):\n",
                "        shutil.copy2(drive_gen_norm_path, local_gen_norm_path)\n",
                "        shutil.copy2(drive_real_norm_path, local_real_norm_path)\n",
                "else:\n",
                "    print(f\"Generating {NUM_SAMPLES} samples...\")\n",
                "    output = !python sample.py --experiment_name {EXPERIMENT_NAME} --dataset {DATASET} --num_samples {NUM_SAMPLES} --sampling_method {SAMPLING_METHOD} --compile_mode {COMPILE_MODE}\n",
                "    print(\"\\n\".join(output))\n",
                "    \n",
                "    if not os.path.exists(local_gen_path):\n",
                "        print(\"\\n❌ Generation failed: Output file not produced.\")\n",
                "        print(\"Possible causes: Checkpoint not found, CUDA error, or config mismatch.\")\n",
                "        raise FileNotFoundError(f\"File does not exist: {local_gen_path}\")\n",
                "\n",
                "    if CACHE_SAMPLES_TO_DRIVE:\n",
                "        os.makedirs(DRIVE_SAMPLES_PATH, exist_ok=True)\n",
                "        shutil.copy2(local_gen_path, drive_gen_path)\n",
                "        shutil.copy2(local_real_path, drive_real_path)\n",
                "        # Cache norm files if they exist\n",
                "        if os.path.exists(local_gen_norm_path):\n",
                "            shutil.copy2(local_gen_norm_path, drive_gen_norm_path)\n",
                "            shutil.copy2(local_real_norm_path, drive_real_norm_path)\n",
                "\n",
                "print(\"✅ Samples Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 4: Initialize Modules\n",
                "import sys\n",
                "import numpy as np\n",
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# --- Evaluation Framework Imports ---\n",
                "from evaluation import visualizations as viz\n",
                "from evaluation import statistics as stats\n",
                "from evaluation import reporting as report\n",
                "from evaluation import wrappers\n",
                "\n",
                "# New Runner for Comprehensive Metrics\n",
                "from evaluation import EvaluationRunner, EvaluationConfig\n",
                "\n",
                "from training import inline_evaluation\n",
                "\n",
                "# Load Dollar Space Data\n",
                "real_path = f\"../outputs/{EXPERIMENT_NAME}/real_samples.npy\"\n",
                "gen_path = f\"../outputs/{EXPERIMENT_NAME}/{SAMPLING_METHOD}_samples.npy\"\n",
                "real_data_full = np.load(real_path)\n",
                "generated_data_full = np.load(gen_path)\n",
                "\n",
                "print(f\"Loaded Full OHLCV (Dollar): Real {real_data_full.shape}, Gen {generated_data_full.shape}\")\n",
                "\n",
                "# Load Reparameterized (Norm) Space Data\n",
                "real_norm_path = f\"../outputs/{EXPERIMENT_NAME}/real_samples_norm.npy\"\n",
                "gen_norm_path = f\"../outputs/{EXPERIMENT_NAME}/{SAMPLING_METHOD}_samples_norm.npy\"\n",
                "HAS_NORM_DATA = os.path.exists(real_norm_path) and os.path.exists(gen_norm_path)\n",
                "\n",
                "if HAS_NORM_DATA:\n",
                "    real_data_norm_full = np.load(real_norm_path)\n",
                "    generated_data_norm_full = np.load(gen_norm_path)\n",
                "    print(f\"Loaded Reparameterized: Real {real_data_norm_full.shape}, Gen {generated_data_norm_full.shape}\")\n",
                "else:\n",
                "    print(\"⚠️ Reparameterized data not found. Re-run sample.py with updated code to generate.\")\n",
                "    real_data_norm_full = None\n",
                "    generated_data_norm_full = None\n",
                "\n",
                "# Downsample for metrics (keep indices consistent)\n",
                "n_s = min(2000, len(real_data_full), len(generated_data_full))\n",
                "np.random.seed(42)\n",
                "real_idx = np.random.choice(len(real_data_full), n_s, replace=False)\n",
                "gen_idx = np.random.choice(len(generated_data_full), n_s, replace=False)\n",
                "\n",
                "# Full OHLCV for sample visualizations (Dollar Space)\n",
                "real_data_ohlcv = real_data_full[real_idx]\n",
                "generated_data_ohlcv = generated_data_full[gen_idx]\n",
                "\n",
                "# Reparameterized subsets\n",
                "real_data_norm = None\n",
                "generated_data_norm = None\n",
                "if HAS_NORM_DATA:\n",
                "    real_data_norm = real_data_norm_full[real_idx]\n",
                "    generated_data_norm = generated_data_norm_full[gen_idx]\n",
                "\n",
                "# Apply EXCLUDE_VOLUME for metrics only\n",
                "if EXCLUDE_VOLUME and real_data_full.shape[2] > 1:\n",
                "    real_data = real_data_ohlcv[..., :-1]\n",
                "    generated_data = generated_data_ohlcv[..., :-1]\n",
                "else:\n",
                "    real_data = real_data_ohlcv\n",
                "    generated_data = generated_data_ohlcv\n",
                "\n",
                "# Prepared Scaled Versions for Visualization\n",
                "dmin, dmax = np.min(real_data, axis=(0,1), keepdims=True), np.max(real_data, axis=(0,1), keepdims=True)\n",
                "real_data_scaled = (real_data - dmin) / (dmax - dmin + 1e-8)\n",
                "generated_data_scaled = (generated_data - dmin) / (dmax - dmin + 1e-8)\n",
                "\n",
                "print(f\"Metrics Data (EXCLUDE_VOLUME={EXCLUDE_VOLUME}): {real_data.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vis_header",
            "metadata": {},
            "source": [
                "### Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vis_run",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Visual Analysis\n",
                "# t-SNE and PCA use scaled OHLC data (no volume)\n",
                "viz.plot_distribution_reduction(real_data_scaled, generated_data_scaled)\n",
                "viz.plot_pdf(real_data_scaled, generated_data_scaled)\n",
                "\n",
                "# Sample plots use FULL OHLCV data in Dollar Space\n",
                "viz.plot_candlesticks(real_data_ohlcv, generated_data_ohlcv)\n",
                "viz.plot_samples(real_data_ohlcv, generated_data_ohlcv)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "metrics_header",
            "metadata": {},
            "source": [
                "### Comprehensive Metrics Evaluation\n",
                "\n",
                "Evaluates model performance metrics including Tier 1 (Core) and Tier 2 (Advanced)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "evaluation_runner_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Run Evaluation Metrics (Using EvaluationRunner)\n",
                "\n",
                "# Configure Evaluation\n",
                "config = EvaluationConfig(\n",
                "    n_iterations=1,                # Iterations for stochastic metrics\n",
                "    exclude_volume=EXCLUDE_VOLUME, # Use the global setting\n",
                "    dtw_n_samples=100,             # Samples for DTW (expensive)\n",
                "    correlation_sample_size=1000   # Samples for Cross-Correlation\n",
                ")\n",
                "\n",
                "runner = EvaluationRunner(config)\n",
                "\n",
                "print(\"Running Full Evaluation...\")\n",
                "# Runner handles scaling and feature extraction internally\n",
                "results = runner.run(\n",
                "    real_dollar=real_data_ohlcv, \n",
                "    synth_dollar=generated_data_ohlcv,\n",
                "    real_reparam=real_data_norm,\n",
                "    synth_reparam=generated_data_norm\n",
                ")\n",
                "\n",
                "print(\"Evaluation Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "scorecard_display",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Display Scorecards\n",
                "from IPython.display import display\n",
                "\n",
                "print(\"\\n--- DOLLAR SPACE SCORECARD ---\")\n",
                "display(report.display_scorecard(results['dollar']))\n",
                "\n",
                "if 'reparam' in results:\n",
                "    print(\"\\n--- REPARAMETERIZED SPACE SCORECARD ---\")\n",
                "    display(report.display_scorecard(results['reparam']))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
# -*- coding: utf-8 -*-
"""TPU_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B59x2OW-0ZrBdkZJN-8Jhv8_Z_AznUH9
"""

# @title Global Configuration
import os

# 1. Select Backend BEFORE importing Keras
# JAX is highly recommended for Keras 3 on both TPU and GPU.
os.environ["KERAS_BACKEND"] = "jax"

# Hyperparameters
BATCH_SIZE = 512  # Per-device batch size
EPOCHS = 20
LEARNING_RATE = 1e-3
NUM_CLASSES = 10
INPUT_SHAPE = (28, 28, 1)

# Dataset Sizes
TRAIN_SIZE = 100000
VAL_SIZE = 10000

# @title Imports & Environment
# Ensure Keras 3 is installed
try:
    import keras
except ImportError:
    !pip install -q --upgrade keras
    import keras

import jax
import os

print(f"Active Backend: {keras.config.backend()}")

# --- Hardware Detection & Distribution Strategy ---
try:
    # JAX automatically detects the accelerator available (TPU or GPU)
    devices = jax.devices()
    device_type = devices[0].platform.upper() # 'TPU', 'GPU', or 'CPU'
    num_devices = len(devices)

    print(f"‚úÖ Hardware Detected: {device_type} (Count: {num_devices})")

    if device_type == 'CPU':
        print("‚ö†Ô∏è No accelerator found. Training will be slow.")
        # No specific distribution needed for single CPU
        GLOBAL_BATCH_SIZE = BATCH_SIZE
    else:
        # Use DataParallel for Multi-GPU or TPU
        # This API works seamlessly for both hardware types
        distribution = keras.distribution.DataParallel(devices=devices)
        keras.distribution.set_distribution(distribution)
        print(f"‚úÖ Distribution Policy: DataParallel enabled on {num_devices} {device_type}s")

        # Scale batch size by number of devices
        GLOBAL_BATCH_SIZE = BATCH_SIZE * num_devices

    print(f"   Global Batch Size: {GLOBAL_BATCH_SIZE}")

except Exception as e:
    print(f"‚ùå Initialization Failed: {e}")
    GLOBAL_BATCH_SIZE = BATCH_SIZE

# @title Data Preparation
import tensorflow as tf
import numpy as np
import jax

# Detect Hardware for specific optimizations
try:
    hw_device = jax.devices()[0]
    hw_type = hw_device.platform.upper()
    hw_details = str(hw_device.device_kind).upper()
except:
    hw_type = "CPU"
    hw_details = "STANDARD"

def get_dataset(size, is_training=True):
    """
    Generates synthetic data optimized for high-throughput L4/A100 and TPU v5/v6.
    """
    print(f"Generating {size} samples for {hw_type} ({hw_details})...")

    # 1. Determine Optimal Transfer DType (PCIe/ICI Optimization)
    # TPU v5e/v6e and A100s ingest bfloat16 twice as fast as float32.
    # We cast on the CPU before transfer to maximize bandwidth.
    if hw_type == 'TPU' or ('A100' in hw_details or 'L4' in hw_details):
        target_dtype = tf.bfloat16
        print("‚ö° Optimization: Using bfloat16 (Native for TPU v5/v6 & Ampere GPUs)")
    elif hw_type == 'GPU':
        target_dtype = tf.float16
        print("‚ö° Optimization: Using float16 (Standard GPU Optimization)")
    else:
        target_dtype = tf.float32

    # 2. Generate in Memory (Float32 initially)
    # Keeping source as float32 in RAM is standard; we cast during the pipeline.
    images = np.random.rand(size, *INPUT_SHAPE).astype(np.float32)
    labels = np.random.randint(0, NUM_CLASSES, size).astype(np.int32)

    # 3. Create Dataset
    dataset = tf.data.Dataset.from_tensor_slices((images, labels))

    # 4. OPTIMIZATION: Cache
    # Cache raw float32 data in RAM. This prevents regenerating data
    # and avoids caching the (potentially larger) graph structures of casted data.
    dataset = dataset.cache()

    # 5. OPTIMIZATION: Disable Order Determinism (Crucial for TPU v5/v6)
    # v5/v6 are so fast they can wait on CPU locks ensuring order.
    # Since we shuffle anyway, we disable this to remove CPU overhead.
    if is_training:
        options = tf.data.Options()
        options.experimental_deterministic = False
        dataset = dataset.with_options(options)

        # Shuffle *before* batching
        dataset = dataset.shuffle(size, reshuffle_each_iteration=True)

    # 6. Batching (Move BEFORE Mapping)
    # drop_remainder=True is MANDATORY for TPUs to enable XLA graph caching.
    dataset = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)

    # 7. OPTIMIZATION: Vectorized Mapping
    # We cast the *entire batch* at once. This reduces CPU instruction overhead
    # significantly compared to casting individual images (Scalar Mapping).
    # This is critical for keeping up with v5/v6 TPU throughput.
    def optimize_transfer(img_batch, lbl_batch):
        img_batch = tf.cast(img_batch, target_dtype)
        return img_batch, lbl_batch

    dataset = dataset.map(optimize_transfer, num_parallel_calls=tf.data.AUTOTUNE)

    # 8. Prefetching
    # Overlap the vector-cast/transfer with the TPU/GPU compute.
    dataset = dataset.prefetch(tf.data.AUTOTUNE)

    return dataset

print("Initializing Hardware-Optimized Data Pipeline...")
train_dataset = get_dataset(TRAIN_SIZE, is_training=True)
val_dataset = get_dataset(VAL_SIZE, is_training=False)
print("‚úÖ Data pipeline ready.")

# @title Model Architecture & Training
import keras
from keras import layers
import jax
import time
import numpy as np

# Try to import TqdmCallback for a nicer progress bar
try:
    from tqdm.keras import TqdmCallback
    has_tqdm = True
except ImportError:
    has_tqdm = False

# --- Hardware Optimization Strategy ---
hw_type = jax.devices()[0].platform.upper()
print(f"üöÄ Hardware Detected: {hw_type}")

# 1. Mixed Precision Policies (The "Amp" equivalent)
if hw_type == 'TPU':
    keras.mixed_precision.set_global_policy("mixed_bfloat16")
    print("‚úÖ Optimization: Precision set to 'mixed_bfloat16' (TPU Native)")
elif hw_type == 'GPU':
    keras.mixed_precision.set_global_policy("mixed_float16")
    print("‚úÖ Optimization: Precision set to 'mixed_float16' (GPU Standard)")
else:
    keras.mixed_precision.set_global_policy("float32")
    print("‚ÑπÔ∏è  Optimization: Precision set to 'float32' (CPU)")

def build_stress_test_model():
    """
    A 'Wide VGG-style' model designed to hit ~50 Million parameters.
    """
    inputs = keras.Input(shape=INPUT_SHAPE)

    # Block 1
    x = layers.Conv2D(64, 3, padding="same", activation="relu")(inputs)
    x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D(2)(x)

    # Block 2
    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D(2)(x)

    # Block 3
    x = layers.Conv2D(512, 3, padding="same", activation="relu")(x)
    x = layers.Conv2D(512, 3, padding="same", activation="relu")(x)
    x = layers.MaxPooling2D(2)(x)

    x = layers.Flatten()(x)

    # Massive Dense Head (Parameter Heavy)
    x = layers.Dense(4096, activation="relu")(x)
    x = layers.Dropout(0.4)(x)
    x = layers.Dense(4096, activation="relu")(x)
    x = layers.Dropout(0.4)(x)
    x = layers.Dense(2048, activation="relu")(x)
    x = layers.Dropout(0.4)(x)

    # Output
    outputs = layers.Dense(NUM_CLASSES, activation="softmax", dtype="float32")(x)

    return keras.Model(inputs, outputs, name="50M_Param_Stress_Test")

# Build Model
model = build_stress_test_model()

# 2. XLA Compilation (The "torch.compile" equivalent)
model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    metrics=["accuracy"],
    jit_compile=True
)

model.summary()

# --- Performance Monitoring Callback ---
class PerformanceMetricsCallback(keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        self.epoch_times = []

    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        duration = time.time() - self.epoch_start_time
        self.epoch_times.append(duration)

    def on_train_end(self, logs=None):
        if not self.epoch_times:
            return

        print(f"\n\nüìä --- HARDWARE PERFORMANCE REPORT ---")

        # 1. Warmup Analysis
        # The first epoch includes XLA Compilation and Graph Tracing overhead.
        warmup_time = self.epoch_times[0]
        print(f"1Ô∏è‚É£  Warmup Epoch (Compilation + JIT): {warmup_time:.2f}s")

        # 2. Steady State Analysis
        # We skip the first epoch to measure pure compute throughput.
        if len(self.epoch_times) > 1:
            steady_times = np.array(self.epoch_times[1:])
            avg_time = np.mean(steady_times)
            median_time = np.median(steady_times)
            std_dev = np.std(steady_times)

            # Throughput calculation (Images per second)
            # TRAIN_SIZE is defined in global config
            throughput = TRAIN_SIZE / avg_time

            print(f"2Ô∏è‚É£  Steady State (Epochs 2-{len(self.epoch_times)}):")
            print(f"   ‚Ä¢ Average Time: {avg_time:.4f}s / epoch")
            print(f"   ‚Ä¢ Median Time:  {median_time:.4f}s / epoch")
            print(f"   ‚Ä¢ Stability:    ¬±{std_dev:.4f}s (Std Dev)")
            print(f"   ‚Ä¢ Throughput:   {throughput:,.1f} images/sec")
        else:
            print("   (Run more epochs to see steady-state performance)")

# Train
print(f"\nStarting Stress Test on {hw_type}...")

# Configure callbacks
callbacks = [PerformanceMetricsCallback()] # Add custom metrics
if has_tqdm:
    callbacks.append(TqdmCallback(verbose=1))
    fit_verbose = 0
else:
    fit_verbose = 1

history = model.fit(
    train_dataset,
    epochs=EPOCHS,
    validation_data=val_dataset,
    verbose=fit_verbose,
    callbacks=callbacks
)
{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "3cf3a097",
            "metadata": {},
            "source": [
                "# WaveletDiff Evaluation Notebook\n",
                "\n",
                "This notebook evaluates a trained WaveletDiff model using various metrics:\n",
                "- Discriminative Score\n",
                "- Predictive Score\n",
                "- Context-FID\n",
                "- Time-Series Correlation\n",
                "- DTW Distance\n",
                "\n",
                "It uses the backend defined in `src/torch_gpu_waveletDiff/eval` and `src/torch_gpu_waveletDiff/inference`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aabc0c6e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 1: Global Configuration\n",
                "\n",
                "# Paths\n",
                "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
                "REPO_DIR = \"/content/waveletDiff_synth_data\" \n",
                "\n",
                "# Checkpoint Path (Update this to your checkpoint in Google Drive)\n",
                "DRIVE_DIR = \"/content/drive/MyDrive/personal_drive/trading\"\n",
                "RUN_NAME = \"stocks_ohlcv_v1_top\"\n",
                "CHECKPOINT_NAME = \"last\"\n",
                "CHECKPOINT_PATH = f\"{DRIVE_DIR}/checkpoints/{RUN_NAME}/{CHECKPOINT_NAME}.ckpt\"\n",
                "\n",
                "# Data Path (Real data for comparison)\n",
                "# If using the one from the repo:\n",
                "DATA_PATH = f\"{REPO_DIR}/src/copied_waveletDiff/data/stocks/stock_data.csv\"\n",
                "# Or if you have a pre-processed .npy file in drive:\n",
                "# DATA_PATH = \"/content/drive/MyDrive/.../real_samples.npy\"\n",
                "\n",
                "OUTPUT_DIR = \"/content/eval_outputs\"\n",
                "NUM_SAMPLES = 2000 # Number of samples to generate and evaluate\n",
                "DEVICE = \"cuda\" # or \"cpu\"\n",
                "BATCH_SIZE = 2000 # Batch size for generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dc5bbda6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 2: Setup (Clone, Install, Mount)\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "import shutil\n",
                "from google.colab import drive\n",
                "\n",
                "# 1. Mount Drive\n",
                "if os.path.exists('/content/drive'):\n",
                "    if not os.listdir('/content/drive'):\n",
                "        drive.mount('/content/drive', force_remount=True)\n",
                "else:\n",
                "    try:\n",
                "        drive.mount('/content/drive')\n",
                "    except:\n",
                "        print(\"Drive mount failed or not in Colab.\")\n",
                "\n",
                "# 2. Clone or Pull Repository\n",
                "if os.path.exists(REPO_DIR):\n",
                "    print(f\"Repo exists at {REPO_DIR}. Pulling latest changes...\")\n",
                "    try:\n",
                "        subprocess.run([\"git\", \"-C\", REPO_DIR, \"pull\"], check=True)\n",
                "    except subprocess.CalledProcessError:\n",
                "         print(\"Git pull failed. Removing and re-cloning...\")\n",
                "         shutil.rmtree(REPO_DIR)\n",
                "         subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
                "else:\n",
                "    print(f\"Cloning {REPO_URL} into {REPO_DIR}...\")\n",
                "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
                "\n",
                "# 3. Install Dependencies\n",
                "print(\"Installing dependencies...\")\n",
                "deps = [\"lightning\", \"pywavelets\", \"scipy\", \"pandas\", \"tqdm\", \"torch_xla[tpu]\" if 'COLAB_TPU_ADDR' in os.environ else \"\"]\n",
                "deps = [d for d in deps if d]\n",
                "subprocess.run([\"pip\", \"install\"] + deps, check=True)\n",
                "\n",
                "# 4. Setup Paths\n",
                "# Main repo root\n",
                "sys.path.append(REPO_DIR)\n",
                "\n",
                "# Add the directory containing 'models', 'data', etc. as a package source.\n",
                "# The loader.py does 'from models.transformer import ...', so 'models' must be a top-level package.\n",
                "src_path = os.path.join(REPO_DIR, \"src\", \"copied_waveletDiff\", \"src\")\n",
                "if src_path not in sys.path:\n",
                "    sys.path.append(src_path)\n",
                "\n",
                "# IMPORTANT: Also enable importing from the root 'src' for torch_gpu_waveletDiff\n",
                "repo_src = os.path.join(REPO_DIR, \"src\")\n",
                "if repo_src not in sys.path:\n",
                "    sys.path.append(repo_src)\n",
                "\n",
                "print(\"Setup Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "416c120c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 3: Run Evaluation\n",
                "import torch\n",
                "import warnings\n",
                "from src.torch_gpu_waveletDiff.eval.evaluator import run_evaluation\n",
                "\n",
                "# Set float32 matmul precision to 'medium' to use Tensor Cores on Ampere+ GPUs\n",
                "torch.set_float32_matmul_precision('medium')\n",
                "\n",
                "# Ensure output directory exists\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "# Run\n",
                "results = run_evaluation(\n",
                "    checkpoint_path=CHECKPOINT_PATH,\n",
                "    data_path=DATA_PATH,\n",
                "    output_dir=OUTPUT_DIR,\n",
                "    num_samples=NUM_SAMPLES,\n",
                "    device=DEVICE,\n",
                "    batch_size=BATCH_SIZE\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "viz_cell_001",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 4: Visualization\n",
                "import glob\n",
                "import numpy as np\n",
                "import os\n",
                "from IPython.display import Image, display\n",
                "from src.torch_gpu_waveletDiff.eval.visualizer import visualize_evaluation\n",
                "\n",
                "print(\"Starting visualization...\")\n",
                "\n",
                "# Find latest generated samples\n",
                "list_of_files = glob.glob(f'{OUTPUT_DIR}/generated_samples_*.npy')\n",
                "if not list_of_files:\n",
                "    print(\"No generated samples found. Please run evaluation first.\")\n",
                "else:\n",
                "    latest_gen_file = max(list_of_files, key=os.path.getctime)\n",
                "    print(f\"Loading generated samples from {latest_gen_file}...\")\n",
                "    generated_data = np.load(latest_gen_file)\n",
                "    \n",
                "    # Find saved real samples\n",
                "    real_file = os.path.join(OUTPUT_DIR, \"real_samples_used.npy\")\n",
                "    if os.path.exists(real_file):\n",
                "        print(f\"Loading real samples from {real_file}...\")\n",
                "        real_data = np.load(real_file)\n",
                "    else:\n",
                "        print(f\"Real samples file not found at {real_file}. Falling back to DATA_PATH...\")\n",
                "        # Fallback might fail for CSV, but it's a backup\n",
                "        try:\n",
                "             real_data = np.load(DATA_PATH)\n",
                "        except:\n",
                "             print(\"Could not load real data from DATA_PATH (likely CSV). Please re-run evaluation to generate 'real_samples_used.npy'.\")\n",
                "             real_data = None\n",
                "\n",
                "    if real_data is not None:\n",
                "        # Run Visualization Backend\n",
                "        visualize_evaluation(real_data, generated_data, OUTPUT_DIR)\n",
                "        \n",
                "        # Display saved plots\n",
                "        print(\"\\n--- Visual Comparisons ---\")\n",
                "        if os.path.exists(f\"{OUTPUT_DIR}/sample_comparison.png\"):\n",
                "            print(\"1. Sample Comparison (Real vs Generated)\")\n",
                "            display(Image(filename=f\"{OUTPUT_DIR}/sample_comparison.png\"))\n",
                "        \n",
                "        if os.path.exists(f\"{OUTPUT_DIR}/distribution_comparison.png\"):\n",
                "            print(\"\\n2. Feature Distribution Comparison\")\n",
                "            display(Image(filename=f\"{OUTPUT_DIR}/distribution_comparison.png\"))\n",
                "            \n",
                "        if os.path.exists(f\"{OUTPUT_DIR}/pca_projection.png\"):\n",
                "            print(\"\\n3. PCA Projection (2D)\")\n",
                "            display(Image(filename=f\"{OUTPUT_DIR}/pca_projection.png\"))\n",
                "    else:\n",
                "        print(\"Skipping visualization due to missing real data.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
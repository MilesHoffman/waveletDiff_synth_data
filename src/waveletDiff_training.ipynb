{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143b80b5",
   "metadata": {},
   "source": [
    "# WaveletDiff Fabric Native Training (High Performance)\n",
    "\n",
    "This notebook implements a clean, high-performance training loop for WaveletDiff using **Lightning Fabric** natively.\n",
    "\n",
    "### Key Optimizations:\n",
    "- **Native Fabric Loop**: Removes overhead of high-level abstractions.\n",
    "- **Smart Gradient Clipping**: Disabled by default for 2x TPU speedup (configurable).\n",
    "- **Efficient Logging**: Metrics are only synchronized periodically (every 1% of progress) to prevent XLA graph breaks.\n",
    "- **BF16 Pre-casting**: Data is cast to BF16 before the loop to maximize TPU throughput.\n",
    "\n",
    "> **Note**: Designed for TPU `v4-8` or `v5e` but compatible with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70fdccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 1: Global Configuration\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Experiment Identity\n",
    "RUN_NAME = \"stocks_ohlcv_v1\" # @param {type:\"string\"}\n",
    "RUN_ID =  f\"{random.randint(0, 999):03d}\"\n",
    "UNIQUE_RUN_NAME = f\"{RUN_NAME}_{RUN_ID}\"\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET_NAME = \"stocks\"\n",
    "SEQ_LEN = 24 # @param {type:\"integer\"}\n",
    "\n",
    "# Model Hyperparameters\n",
    "EMBED_DIM = 256 # @param {type:\"integer\"}\n",
    "NUM_HEADS = 8 # @param {type:\"integer\"}\n",
    "NUM_LAYERS = 8 # @param {type:\"integer\"}\n",
    "TIME_EMBED_DIM = 128 # @param {type:\"integer\"}\n",
    "DROPOUT = 0.1 # @param {type:\"number\"}\n",
    "PREDICTION_TARGET = \"noise\"\n",
    "USE_CROSS_LEVEL_ATTENTION = True # @param {type:\"boolean\"}\n",
    "\n",
    "# Training Parameters\n",
    "TOTAL_TRAINING_STEPS = 15000 # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 512 # @param {type:\"integer\"}\n",
    "LEARNING_RATE = 2e-4 # @param {type:\"number\"}\n",
    "WEIGHT_DECAY = 1e-5 # @param {type:\"number\"}\n",
    "WARMUP_STEPS = int(.05 * TOTAL_TRAINING_STEPS) # @param\n",
    "ENABLE_GRAD_CLIPPING = True # @param {type:\"boolean\"}\n",
    "\n",
    "# === PROFILER CONFIGURATION (NEW) ===\n",
    "ENABLE_PROFILER = False # @param {type:\"boolean\"}\n",
    "PROFILER_WARMUP = 25\n",
    "PROFILER_ACTIVE = 5\n",
    "\n",
    "# Logging & Checkpointing\n",
    "# Set dynamically to 1% of training progress\n",
    "LOG_INTERVAL = max(1, int(TOTAL_TRAINING_STEPS * 0.01))\n",
    "SAVE_INTERVAL = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "# Wavelet Configuration\n",
    "WAVELET_TYPE = \"db2\" # @param {type:\"string\"}\n",
    "WAVELET_LEVELS = \"auto\"\n",
    "\n",
    "# Paths\n",
    "DRIVE_BASE_PATH = \"/content/drive/MyDrive/personal_drive/trading\"\n",
    "CHECKPOINT_DIR = f\"{DRIVE_BASE_PATH}/checkpoints/{UNIQUE_RUN_NAME}\"\n",
    "REPO_DIR = \"/content/WaveletDiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7568976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n",
      "INFO: Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Directory Verified: /content/drive/MyDrive/personal_drive/trading/checkpoints/stocks_ohlcv_v1_865\n",
      "[Rank 0] Fabric initialized on device: cuda:0 with precision: bf16-mixed\n"
     ]
    }
   ],
   "source": [
    "# @title Cell 2: Imports & Fabric Initialization\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# === CRITICAL: FORCE GOOGLE DRIVE MOUNT ===\n",
    "# We do this FIRST to ensure checkpoints go to persistent storage.\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    if os.path.exists('/content/drive'):\n",
    "        # Check if it's actually mounted (if empty, it might be a ghost dir)\n",
    "        if not os.listdir('/content/drive'):\n",
    "            print(\"Detected ghost directory. Force remounting...\")\n",
    "            drive.mount('/content/drive', force_remount=True)\n",
    "    else:\n",
    "        drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    print(\"Not running on Colab. Skipping Drive mount.\")\n",
    "except Exception as e:\n",
    "    print(f\"Drive mount warning: {e}\")\n",
    "\n",
    "# 1. Performance Polishing: Set Matmul Precision for GPUs (Ampere+/L4/A100)\n",
    "if torch.cuda.is_available():\n",
    "    # 'high' uses TensorFloat-32 (TF32) for significantly faster matmuls on L4/A100\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# 2. Conditional Dependency Installation\n",
    "deps = [\"lightning\", \"pywavelets\", \"scipy\", \"pandas\", \"tqdm\"]\n",
    "\n",
    "# STRICT CHECK: Only install torch_xla if explicitly on a TPU environment\n",
    "is_tpu = 'COLAB_TPU_ADDR' in os.environ or 'TPU_NAME' in os.environ\n",
    "if is_tpu and not any(\"torch_xla\" in line for line in subprocess.getoutput(\"pip list\").splitlines()):\n",
    "    deps.append(\"torch_xla[tpu]\")\n",
    "\n",
    "try:\n",
    "    import lightning.fabric\n",
    "except ImportError:\n",
    "    print(f\"Installing dependencies ({', '.join(deps)})...\")\n",
    "    subprocess.run([\"pip\", \"install\"] + deps, check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "import lightning as L\n",
    "from lightning.fabric import Fabric\n",
    "\n",
    "# 3. Dynamic Precision Detection\n",
    "if is_tpu:\n",
    "    PRECISION = \"bf16-true\"\n",
    "elif torch.cuda.is_available():\n",
    "    PRECISION = \"bf16-mixed\"\n",
    "else:\n",
    "    PRECISION = \"bf16-true\"\n",
    "\n",
    "# 4. Initialize Fabric\n",
    "# Note: logical_cpu_count is safer for shared environments\n",
    "fabric = Fabric(accelerator=\"auto\", devices=\"auto\", precision=PRECISION)\n",
    "fabric.launch()\n",
    "\n",
    "# 5. Clone Repository\n",
    "# We need to ensure REPO_DIR is defined. It usually comes from Cell 1.\n",
    "# We assume Cell 1 has run.\n",
    "if 'REPO_DIR' not in globals():\n",
    "    REPO_DIR = \"/content/WaveletDiff\" # Fallback\n",
    "\n",
    "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    if fabric.is_global_zero:\n",
    "        print(f\"Cloning {REPO_URL}...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True, stdout=subprocess.DEVNULL)\n",
    "    fabric.barrier() # Wait for clone\n",
    "\n",
    "# 6. Add to System Path (Revised for new repo structure)\n",
    "sys.path.append(os.path.join(REPO_DIR, \"WaveletDiff_source\", \"src\"))\n",
    "\n",
    "# 7. Create Checkpoint Directory\n",
    "# We assume CHECKPOINT_DIR is defined in Cell 1.\n",
    "if 'CHECKPOINT_DIR' in globals():\n",
    "    if fabric.is_global_zero:\n",
    "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "        print(f\"Checkpoint Directory Verified: {CHECKPOINT_DIR}\")\n",
    "\n",
    "print(f\"[Rank {fabric.global_rank}] Fabric initialized on device: {fabric.device} with precision: {PRECISION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /content/WaveletDiff/WaveletDiff_source/data/stocks/stock_data.csv...\n",
      "Raw Data Tensor Shape: torch.Size([3662, 24, 5])\n",
      "Converting to wavelet coefficients with 3 levels...\n",
      "Coefficient shapes per level: [(5,), (5,), (8,), (13,)]\n",
      "Level dimensions: [np.int64(5), np.int64(5), np.int64(8), np.int64(13)]\n",
      "Total coefficients per feature: 31\n",
      "Converted torch.Size([3662, 24, 5]) time series to torch.Size([3662, 31, 5]) wavelet coefficients\n",
      "Wavelet: db2, Levels: 3\n",
      "Using 4 num_workers...\n"
     ]
    }
   ],
   "source": [
    "# @title Cell 3: Data Loading (Fabric Optimized)\n",
    "import pandas as pd\n",
    "from data.loaders import create_sliding_windows\n",
    "from data.module import WaveletTimeSeriesDataModule\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import multiprocessing\n",
    "\n",
    "def get_dataloaders():\n",
    "    \"\"\"Setup DataModule and return optimal Fabric DataLoader\"\"\"\n",
    "    stocks_path = os.path.join(REPO_DIR, \"WaveletDiff_source\", \"data\", \"stocks\", \"stock_data.csv\")\n",
    "\n",
    "    if fabric.is_global_zero:\n",
    "        print(f\"Loading data from {stocks_path}...\")\n",
    "\n",
    "    df = pd.read_csv(stocks_path)\n",
    "    CORE_COLS = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df_filtered = df[CORE_COLS]\n",
    "\n",
    "    # Create windows (Memory intensive, so we do it on CPU)\n",
    "    custom_data_windows, _ = create_sliding_windows(\n",
    "        df_filtered.values,\n",
    "        seq_len=SEQ_LEN,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    full_data_tensor = torch.FloatTensor(custom_data_windows)\n",
    "\n",
    "    # CONFIG\n",
    "    full_config = {\n",
    "        'dataset': {'name': DATASET_NAME, 'seq_len': SEQ_LEN},\n",
    "        'training': {'batch_size': BATCH_SIZE, 'epochs': 1},\n",
    "        'data': {'data_dir': os.path.join(REPO_DIR, \"WaveletDiff_source\", \"data\"), 'normalize_data': False},\n",
    "        'wavelet': {'type': WAVELET_TYPE, 'levels': WAVELET_LEVELS}\n",
    "    }\n",
    "\n",
    "    # Create DataModule (Handles Wavelet Transforms internally during init if needed, or we use it for metadata)\n",
    "    datamodule = WaveletTimeSeriesDataModule(config=full_config, data_tensor=full_data_tensor)\n",
    "\n",
    "    # XLA/GPU OPTIMIZATION: Cast to target dtype BEFORE creating dataset to avoid cast overhead in loop\n",
    "    if PRECISION == \"bf16-true\" and fabric.device.type != \"cpu\":\n",
    "        if fabric.is_global_zero: print(f\"Optimizing: Casting data to bfloat16 for {fabric.device.type}...\")\n",
    "        full_data_tensor = full_data_tensor.to(torch.bfloat16)\n",
    "\n",
    "    dataset = TensorDataset(full_data_tensor)\n",
    "\n",
    "    # WORKER CONFIGURATION\n",
    "    # We use minimal workers to avoid overhead, but >0 to ensure prefetching.\n",
    "    # On Colab (2 vCPU), usually 2 is max. On larger nodes, 4-8 is good.\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    num_workers = min(4, max(0, cpu_count - 2))\n",
    "    print(f\"Using {num_workers} num_workers...\")\n",
    "\n",
    "    # DataLoader\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True, # Important for XLA compilation stability\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if fabric.device.type == \"cuda\" else False, # Pin only on CUDA\n",
    "        persistent_workers=True if num_workers > 0 else False\n",
    "    )\n",
    "\n",
    "    # Fabric Setup (Handles Sharding/Distributed Sampler)\n",
    "    loader = fabric.setup_dataloaders(loader)\n",
    "\n",
    "    return loader, datamodule, full_config\n",
    "\n",
    "train_loader, datamodule, model_base_config = get_dataloaders()\n",
    "WAVELET_INFO = datamodule.get_wavelet_info()\n",
    "INPUT_DIM = datamodule.get_input_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670ff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized coefficient_weighted wavelet loss:\n",
      "  Level 0: 5 coeffs, weight=0.4988\n",
      "  Level 1: 5 coeffs, weight=0.2494\n",
      "  Level 2: 8 coeffs, weight=0.1559\n",
      "  Level 3: 13 coeffs, weight=0.0959\n",
      "Using coefficient_weighted loss strategy (no energy term)\n",
      "Created 4 level-specific transformers (Channel-based):\n",
      "  Level 0: 5 coefficients, 512 embed_dim, 10 layers\n",
      "  Level 1: 5 coefficients, 256 embed_dim, 8 layers\n",
      "  Level 2: 8 coefficients, 256 embed_dim, 8 layers\n",
      "  Level 3: 13 coefficients, 256 embed_dim, 8 layers\n",
      "Cross-level attention enabled with common dimension: 512\n",
      "\n",
      "============================================================\n",
      "WAVELET DIFFUSION TRANSFORMER MODEL INFO\n",
      "============================================================\n",
      "Dataset: stocks\n",
      "Input dimension: 31\n",
      "Embedding dimension: 256\n",
      "Time embedding dimension: 128\n",
      "Prediction target: noise\n",
      "Noise schedule: exponential\n",
      "Cross-level attention: Enabled\n",
      "Number of wavelet levels: 4\n",
      "\n",
      "Wavelet level details:\n",
      "  Level 0: 5 coefficients, shape (5,)\n",
      "  Level 1: 5 coefficients, shape (5,)\n",
      "  Level 2: 8 coefficients, shape (8,)\n",
      "  Level 3: 13 coefficients, shape (13,)\n",
      "\n",
      "Energy Loss Configuration:\n",
      "Energy term enabled: False\n",
      "============================================================\n",
      "\n",
      "Initialized exponential noise schedule\n",
      "[Rank 0] Moving model to cuda:0...\n",
      "[Rank 0] Applying torch.compile(mode='reduce-overhead')...\n",
      "[Rank 0] Note: You will see a ~60s delay at Step 0 while kernels are built.\n",
      "[Rank 0] Using Fused AdamW...\n"
     ]
    }
   ],
   "source": [
    "# @title Cell 4: Model Initialization (Optimized Sandwich)\n",
    "from models.transformer import WaveletDiffusionTransformer\n",
    "\n",
    "# Update Config\n",
    "model_base_config.update({\n",
    "    'model': {\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'time_embed_dim': TIME_EMBED_DIM,\n",
    "        'dropout': DROPOUT,\n",
    "        'prediction_target': PREDICTION_TARGET\n",
    "    },\n",
    "    'attention': {'use_cross_level_attention': USE_CROSS_LEVEL_ATTENTION},\n",
    "    'noise': {'schedule': \"exponential\"},\n",
    "    'sampling': {'ddim_eta': 0.0, 'ddim_steps': None},\n",
    "    'energy': {'weight': 0.0},\n",
    "    'optimizer': {\n",
    "        'scheduler_type': 'onecycle',\n",
    "        'lr': LEARNING_RATE,\n",
    "        'warmup_epochs': 5,\n",
    "        'cosine_eta_min': 1e-6\n",
    "    }\n",
    "})\n",
    "\n",
    "def init_system():\n",
    "    # 1. Instantiate (CPU)\n",
    "    model = WaveletDiffusionTransformer(data_module=datamodule, config=model_base_config)\n",
    "\n",
    "    # 2. DEVICE PLACEMENT (Manual)\n",
    "    # Critical: Move to device BEFORE compiling so we generate CUDA graphs, not CPU graphs.\n",
    "    if fabric.is_global_zero: print(f\"[Rank 0] Moving model to {fabric.device}...\")\n",
    "    model.to(fabric.device)\n",
    "\n",
    "    # 3. COMPILATION (Before Setup)\n",
    "    # We compile the raw model. If this crashes, change mode to \"default\".\n",
    "    if fabric.device.type == \"cuda\":\n",
    "        # 'reduce-overhead' is critical for fixing the dispatch bottleneck (High CPU/GPU ratio)\n",
    "        # It uses CUDA Graphs. If this hangs > 3 mins, switch to 'default' or 'max-autotune'.\n",
    "        COMPILE_MODE = \"reduce-overhead\"\n",
    "\n",
    "        print(f\"[Rank 0] Applying torch.compile(mode='{COMPILE_MODE}')...\")\n",
    "        print(\"[Rank 0] Note: You will see a ~60s delay at Step 0 while kernels are built.\")\n",
    "\n",
    "        try:\n",
    "            model = torch.compile(model, mode=COMPILE_MODE)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Compilation failed: {e}. Falling back to eager execution.\")\n",
    "\n",
    "    # 4. OPTIMIZER (Fused)\n",
    "    # 'fused=True' collapses optimizer kernels (huge win for kernel overhead)\n",
    "    use_fused = fabric.device.type == \"cuda\"\n",
    "    if fabric.is_global_zero and use_fused: print(\"[Rank 0] Using Fused AdamW...\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        fused=use_fused\n",
    "    )\n",
    "\n",
    "    # 5. FABRIC SETUP\n",
    "    # Fabric will see the compiled model and wrap it appropriately.\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "\n",
    "    # 6. REGISTER CUSTOM ENTRY POINT (CRITICAL FIX)\n",
    "    # Fabric requires us to whitelist any method that acts like forward()\n",
    "    # so it can apply the correct strategies (DDP sync, precision, etc.)\n",
    "    model.mark_forward_method('compute_loss')\n",
    "\n",
    "    return model, optimizer\n",
    "\n",
    "model, optimizer = init_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e35925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574f778a135d4f7e863a2333d83854bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CUDA Training:   0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step   150 |   1%] loss: 0.5553 | lr: 3.41e-05\n",
      "[Step   300 |   2%] loss: 0.1828 | lr: 4.04e-05\n",
      "[Step   450 |   3%] loss: 0.1317 | lr: 5.08e-05\n",
      "[Step   600 |   4%] loss: 0.1030 | lr: 6.52e-05\n",
      "[Step   750 |   5%] loss: 0.0858 | lr: 8.35e-05\n",
      "[Step   900 |   6%] loss: 0.0749 | lr: 1.05e-04\n",
      "[Step  1050 |   7%] loss: 0.0660 | lr: 1.31e-04\n",
      "[Step  1200 |   8%] loss: 0.0621 | lr: 1.59e-04\n",
      "[Step  1350 |   9%] loss: 0.0583 | lr: 1.90e-04\n",
      "[Step  1500 |  10%] loss: 0.0555 | lr: 2.24e-04\n",
      "[Step  1650 |  11%] loss: 0.0535 | lr: 2.60e-04\n",
      "[Step  1800 |  12%] loss: 0.0518 | lr: 2.97e-04\n",
      "[Step  1950 |  13%] loss: 0.0505 | lr: 3.36e-04\n",
      "[Step  2100 |  14%] loss: 0.0495 | lr: 3.76e-04\n",
      "[Step  2250 |  15%] loss: 0.0485 | lr: 4.16e-04\n",
      "[Step  2400 |  16%] loss: 0.0472 | lr: 4.56e-04\n",
      "[Step  2550 |  17%] loss: 0.0471 | lr: 4.96e-04\n",
      "[Step  2700 |  18%] loss: 0.0470 | lr: 5.35e-04\n",
      "[Step  2850 |  19%] loss: 0.0453 | lr: 5.72e-04\n",
      "[Step  3000 |  20%] loss: 0.0450 | lr: 6.08e-04\n",
      "[Step  3150 |  21%] loss: 0.0454 | lr: 6.42e-04\n",
      "[Step  3300 |  22%] loss: 0.0441 | lr: 6.73e-04\n",
      "[Step  3450 |  23%] loss: 0.0439 | lr: 7.02e-04\n",
      "[Step  3600 |  24%] loss: 0.0429 | lr: 7.27e-04\n",
      "[Step  3750 |  25%] loss: 0.0425 | lr: 7.49e-04\n",
      "[Step  3900 |  26%] loss: 0.0414 | lr: 7.67e-04\n",
      "[Step  4050 |  27%] loss: 0.0423 | lr: 7.81e-04\n",
      "[Step  4200 |  28%] loss: 0.0413 | lr: 7.92e-04\n",
      "[Step  4350 |  29%] loss: 0.0408 | lr: 7.98e-04\n",
      "[Step  4500 |  30%] loss: 0.0401 | lr: 8.00e-04\n",
      "[Step  4650 |  31%] loss: 0.0402 | lr: 8.00e-04\n",
      "[Step  4800 |  32%] loss: 0.0399 | lr: 7.98e-04\n",
      "[Step  4950 |  33%] loss: 0.0399 | lr: 7.96e-04\n",
      "\n",
      "Saved checkpoint to /content/drive/MyDrive/personal_drive/trading/checkpoints/stocks_ohlcv_v1_865/step_5000.ckpt\n",
      "[Step  5100 |  34%] loss: 0.0392 | lr: 7.94e-04\n",
      "[Step  5250 |  35%] loss: 0.0386 | lr: 7.90e-04\n",
      "[Step  5400 |  36%] loss: 0.0384 | lr: 7.86e-04\n",
      "[Step  5550 |  37%] loss: 0.0384 | lr: 7.80e-04\n",
      "[Step  5700 |  38%] loss: 0.0386 | lr: 7.74e-04\n",
      "[Step  5850 |  39%] loss: 0.0374 | lr: 7.68e-04\n",
      "[Step  6000 |  40%] loss: 0.0376 | lr: 7.60e-04\n",
      "[Step  6150 |  41%] loss: 0.0373 | lr: 7.52e-04\n",
      "[Step  6300 |  42%] loss: 0.0371 | lr: 7.43e-04\n",
      "[Step  6450 |  43%] loss: 0.0370 | lr: 7.34e-04\n",
      "[Step  6600 |  44%] loss: 0.0368 | lr: 7.24e-04\n",
      "[Step  6750 |  45%] loss: 0.0371 | lr: 7.13e-04\n",
      "[Step  6900 |  46%] loss: 0.0367 | lr: 7.01e-04\n",
      "[Step  7050 |  47%] loss: 0.0358 | lr: 6.89e-04\n",
      "[Step  7200 |  48%] loss: 0.0363 | lr: 6.76e-04\n",
      "[Step  7350 |  49%] loss: 0.0360 | lr: 6.63e-04\n",
      "[Step  7500 |  50%] loss: 0.0360 | lr: 6.49e-04\n",
      "[Step  7650 |  51%] loss: 0.0356 | lr: 6.35e-04\n",
      "[Step  7800 |  52%] loss: 0.0352 | lr: 6.20e-04\n",
      "[Step  7950 |  53%] loss: 0.0349 | lr: 6.05e-04\n",
      "[Step  8100 |  54%] loss: 0.0344 | lr: 5.89e-04\n",
      "[Step  8250 |  55%] loss: 0.0348 | lr: 5.73e-04\n",
      "[Step  8400 |  56%] loss: 0.0348 | lr: 5.57e-04\n",
      "[Step  8550 |  57%] loss: 0.0347 | lr: 5.40e-04\n",
      "[Step  8700 |  58%] loss: 0.0345 | lr: 5.23e-04\n",
      "[Step  8850 |  59%] loss: 0.0341 | lr: 5.06e-04\n",
      "[Step  9000 |  60%] loss: 0.0337 | lr: 4.89e-04\n",
      "[Step  9150 |  61%] loss: 0.0339 | lr: 4.71e-04\n",
      "[Step  9300 |  62%] loss: 0.0338 | lr: 4.54e-04\n",
      "[Step  9450 |  63%] loss: 0.0335 | lr: 4.36e-04\n",
      "[Step  9600 |  64%] loss: 0.0338 | lr: 4.18e-04\n",
      "[Step  9750 |  65%] loss: 0.0330 | lr: 4.00e-04\n",
      "[Step  9900 |  66%] loss: 0.0332 | lr: 3.82e-04\n",
      "\n",
      "Saved checkpoint to /content/drive/MyDrive/personal_drive/trading/checkpoints/stocks_ohlcv_v1_865/step_10000.ckpt\n",
      "[Step 10050 |  67%] loss: 0.0327 | lr: 3.64e-04\n",
      "[Step 10200 |  68%] loss: 0.0329 | lr: 3.46e-04\n",
      "[Step 10350 |  69%] loss: 0.0330 | lr: 3.28e-04\n",
      "[Step 10500 |  70%] loss: 0.0323 | lr: 3.11e-04\n",
      "[Step 10650 |  71%] loss: 0.0324 | lr: 2.93e-04\n",
      "[Step 10800 |  72%] loss: 0.0322 | lr: 2.76e-04\n",
      "[Step 10950 |  73%] loss: 0.0326 | lr: 2.59e-04\n",
      "[Step 11100 |  74%] loss: 0.0324 | lr: 2.43e-04\n",
      "[Step 11250 |  75%] loss: 0.0318 | lr: 2.26e-04\n",
      "[Step 11400 |  76%] loss: 0.0316 | lr: 2.10e-04\n",
      "[Step 11550 |  77%] loss: 0.0320 | lr: 1.95e-04\n",
      "[Step 11700 |  78%] loss: 0.0318 | lr: 1.80e-04\n",
      "[Step 11850 |  79%] loss: 0.0312 | lr: 1.65e-04\n",
      "[Step 12000 |  80%] loss: 0.0308 | lr: 1.51e-04\n",
      "[Step 12150 |  81%] loss: 0.0312 | lr: 1.37e-04\n",
      "[Step 12300 |  82%] loss: 0.0312 | lr: 1.23e-04\n",
      "[Step 12450 |  83%] loss: 0.0312 | lr: 1.11e-04\n",
      "[Step 12600 |  84%] loss: 0.0313 | lr: 9.87e-05\n",
      "[Step 12750 |  85%] loss: 0.0308 | lr: 8.72e-05\n",
      "[Step 12900 |  86%] loss: 0.0311 | lr: 7.63e-05\n",
      "[Step 13050 |  87%] loss: 0.0305 | lr: 6.61e-05\n",
      "[Step 13200 |  88%] loss: 0.0303 | lr: 5.66e-05\n",
      "[Step 13350 |  89%] loss: 0.0303 | lr: 4.77e-05\n",
      "[Step 13500 |  90%] loss: 0.0304 | lr: 3.96e-05\n",
      "[Step 13650 |  91%] loss: 0.0300 | lr: 3.21e-05\n",
      "[Step 13800 |  92%] loss: 0.0296 | lr: 2.55e-05\n",
      "[Step 13950 |  93%] loss: 0.0302 | lr: 1.95e-05\n",
      "[Step 14100 |  94%] loss: 0.0300 | lr: 1.44e-05\n",
      "[Step 14250 |  95%] loss: 0.0299 | lr: 1.00e-05\n",
      "[Step 14400 |  96%] loss: 0.0300 | lr: 6.41e-06\n",
      "[Step 14550 |  97%] loss: 0.0300 | lr: 3.61e-06\n",
      "[Step 14700 |  98%] loss: 0.0300 | lr: 1.60e-06\n",
      "[Step 14850 |  99%] loss: 0.0296 | lr: 4.01e-07\n",
      "[Step 15000 | 100%] loss: 0.0303 | lr: 3.22e-09\n",
      "\n",
      "Saved checkpoint to /content/drive/MyDrive/personal_drive/trading/checkpoints/stocks_ohlcv_v1_865/step_15000.ckpt\n",
      "Training/Profiling Finished.\n"
     ]
    }
   ],
   "source": [
    "# @title Cell 5: Native Fabric Training Loop (Hardened)\n",
    "from contextlib import nullcontext\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule, tensorboard_trace_handler\n",
    "import math\n",
    "\n",
    "def train_loop():\n",
    "    # 1. Determine Effective Steps\n",
    "    if ENABLE_PROFILER:\n",
    "        effective_steps = PROFILER_WARMUP + PROFILER_ACTIVE + 2\n",
    "        print(f\"[Rank {fabric.global_rank}] PROFILER ENABLED: Overriding total steps to {effective_steps}\")\n",
    "    else:\n",
    "        effective_steps = TOTAL_TRAINING_STEPS\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=LEARNING_RATE * 4,\n",
    "        total_steps=TOTAL_TRAINING_STEPS,\n",
    "        pct_start=0.3\n",
    "    )\n",
    "\n",
    "    train_iter = iter(train_loader)\n",
    "\n",
    "    if fabric.is_global_zero:\n",
    "        desc = \"PROFILING\" if ENABLE_PROFILER else f\"{fabric.device.type.upper()} Training\"\n",
    "        pbar = tqdm(range(effective_steps), desc=desc)\n",
    "    else:\n",
    "        pbar = range(effective_steps)\n",
    "\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 2. Profiler Context\n",
    "    if ENABLE_PROFILER:\n",
    "        activities = [ProfilerActivity.CPU]\n",
    "        if torch.cuda.is_available(): activities.append(ProfilerActivity.CUDA)\n",
    "        prof_schedule = schedule(wait=1, warmup=PROFILER_WARMUP, active=PROFILER_ACTIVE, repeat=1)\n",
    "        handler = tensorboard_trace_handler('./log/profiler')\n",
    "        profiler_ctx = profile(\n",
    "            activities=activities, schedule=prof_schedule, on_trace_ready=handler,\n",
    "            record_shapes=False, profile_memory=False, with_stack=True\n",
    "        )\n",
    "    else:\n",
    "        profiler_ctx = nullcontext()\n",
    "\n",
    "    # 3. Main Loop\n",
    "    with profiler_ctx as prof:\n",
    "        for step in pbar:\n",
    "\n",
    "            # MARKER: Data Loading\n",
    "            with record_function(\"data_loading\"):\n",
    "                try:\n",
    "                    batch = next(train_iter)\n",
    "                except StopIteration:\n",
    "                    train_iter = iter(train_loader)\n",
    "                    batch = next(train_iter)\n",
    "                x_0 = batch[0]\n",
    "\n",
    "            # MARKER: Forward & Loss\n",
    "            optimizer.zero_grad()\n",
    "            with record_function(\"forward_pass\"):\n",
    "                t = torch.randint(0, model.T, (x_0.size(0),), device=fabric.device)\n",
    "                loss = model.compute_loss(x_0, t)\n",
    "\n",
    "            # MARKER: Backward\n",
    "            with record_function(\"backward_pass\"):\n",
    "                fabric.backward(loss)\n",
    "\n",
    "            # MARKER: Optimization\n",
    "            with record_function(\"optimizer_step\"):\n",
    "                if ENABLE_GRAD_CLIPPING:\n",
    "                    # CRITICAL FIX: error_if_nonfinite=False\n",
    "                    # If gradients explode to Inf, this scales them back to max_norm (1.0)\n",
    "                    # instead of crashing the training run.\n",
    "                    fabric.clip_gradients(model, optimizer, max_norm=1.0, error_if_nonfinite=False)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # 4. Logging\n",
    "            # Accumulate running loss\n",
    "            # loss.item() syncs CPU/GPU, but we need it for logging anyway.\n",
    "            current_loss = loss.item()\n",
    "\n",
    "            running_loss += current_loss\n",
    "\n",
    "            if (step + 1) % LOG_INTERVAL == 0 and not ENABLE_PROFILER:\n",
    "                avg_loss = running_loss / LOG_INTERVAL\n",
    "                if fabric.world_size > 1:\n",
    "                    avg_loss = fabric.all_reduce(avg_loss, reduce_op=\"mean\")\n",
    "\n",
    "                if fabric.is_global_zero:\n",
    "                    current_lr = scheduler.get_last_lr()[0]\n",
    "                    pct = ((step + 1) / TOTAL_TRAINING_STEPS) * 100\n",
    "                    fabric.print(f\"[Step {step+1:5d} | {pct:3.0f}%] loss: {avg_loss:.4f} | lr: {current_lr:.2e}\")\n",
    "                    pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"lr\": f\"{current_lr:.2e}\"})\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "            # 5. Checkpointing\n",
    "            if (step + 1) % SAVE_INTERVAL == 0 and not ENABLE_PROFILER:\n",
    "                save_path = os.path.join(CHECKPOINT_DIR, f\"step_{step+1}.ckpt\")\n",
    "                state = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "                fabric.save(save_path, state)\n",
    "                if fabric.is_global_zero:\n",
    "                    print(f\"\\nSaved checkpoint to {save_path}\", flush=True)\n",
    "\n",
    "            # 6. Step Profiler\n",
    "            if ENABLE_PROFILER:\n",
    "                prof.step()\n",
    "\n",
    "    print(\"Training/Profiling Finished.\")\n",
    "\n",
    "    if ENABLE_PROFILER and fabric.is_global_zero:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PROFILING QUICK REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=15))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sanity check samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46404329ae1146ae9167b3ea3e72a064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/_inductor/lowering.py:7242: UserWarning: \n",
      "Online softmax is disabled on the fly since Inductor decides to\n",
      "split the reduction. Cut an issue to PyTorch if this is an\n",
      "important use case and you want to speed it up with online\n",
      "softmax.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling complete. Converting to time series...\n",
      "Generated samples shape: torch.Size([2, 24, 5])\n"
     ]
    }
   ],
   "source": [
    "# @title Cell 6: Brief Evaluation (Sanity Check)\n",
    "\n",
    "def sanity_check_sampling():\n",
    "    # Generate a few samples to ensure model learned something\n",
    "    model.eval()\n",
    "    num_samples = 2\n",
    "    print(\"Generating sanity check samples...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Start from random noise in wavelet domain\n",
    "        shape = (num_samples, INPUT_DIM, WAVELET_INFO['n_features'])\n",
    "        samples_wavelet = torch.randn(shape, device=fabric.device, dtype=torch.bfloat16)\n",
    "\n",
    "        # Reverse diffusion\n",
    "        for i in tqdm(reversed(range(model.T)), total=model.T, desc=\"Sampling\", disable=not fabric.is_global_zero):\n",
    "            t = torch.full((num_samples,), i, device=fabric.device, dtype=torch.long)\n",
    "            t_norm = t.float() / model.T\n",
    "\n",
    "            eps_theta = model(samples_wavelet, t_norm)\n",
    "\n",
    "            # Standard DDPM update (simplified)\n",
    "            alpha_t = model.alpha_all[t].view(-1, 1, 1)\n",
    "            alpha_bar_t = model.alpha_bar_all[t].view(-1, 1, 1)\n",
    "            beta_t = model.beta_all[t].view(-1, 1, 1)\n",
    "\n",
    "            mean = (1 / torch.sqrt(alpha_t)) * (\n",
    "                samples_wavelet - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * eps_theta\n",
    "            )\n",
    "\n",
    "            if i > 0:\n",
    "                noise = torch.randn_like(samples_wavelet)\n",
    "                samples_wavelet = mean + torch.sqrt(beta_t) * noise\n",
    "            else:\n",
    "                samples_wavelet = mean\n",
    "\n",
    "    print(\"Sampling complete. Converting to time series...\")\n",
    "    # Convert back to time series (ensure cpu float32 for reconstruction stability)\n",
    "    samples_wavelet_cpu = samples_wavelet.float().cpu()\n",
    "    samples_ts = datamodule.convert_wavelet_to_timeseries(samples_wavelet_cpu)\n",
    "    print(f\"Generated samples shape: {samples_ts.shape}\")\n",
    "    return samples_ts\n",
    "\n",
    "if fabric.is_global_zero:\n",
    "    samples = sanity_check_sampling()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

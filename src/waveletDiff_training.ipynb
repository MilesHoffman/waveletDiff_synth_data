{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe82947b",
   "metadata": {},
   "source": [
    "# WaveletDiff Fabric Native Training (High Performance)\n",
    "\n",
    "This notebook implements a clean, high-performance training loop for WaveletDiff using **Lightning Fabric** natively. \n",
    "\n",
    "### Key Optimizations:\n",
    "- **Native Fabric Loop**: Removes overhead of high-level abstractions.\n",
    "- **Smart Gradient Clipping**: Disabled by default for 2x TPU speedup (configurable).\n",
    "- **Efficient Logging**: Metrics are only synchronized periodically (every 1% of progress) to prevent XLA graph breaks.\n",
    "- **BF16 Pre-casting**: Data is cast to BF16 before the loop to maximize TPU throughput.\n",
    "\n",
    "> **Note**: Designed for TPU `v4-8` or `v5e` but compatible with GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4542ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 1: Global Configuration\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Experiment Identity\n",
    "RUN_NAME = \"fabric_native_v1\" # @param {type:\"string\"}\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "UNIQUE_RUN_NAME = f\"{RUN_NAME}_{RUN_ID}\"\n",
    "\n",
    "# Dataset Configuration\n",
    "DATASET_NAME = \"stocks\"\n",
    "SEQ_LEN = 24 # @param {type:\"integer\"}\n",
    "\n",
    "# Model Hyperparameters\n",
    "EMBED_DIM = 256 # @param {type:\"integer\"}\n",
    "NUM_HEADS = 8 # @param {type:\"integer\"}\n",
    "NUM_LAYERS = 8 # @param {type:\"integer\"}\n",
    "TIME_EMBED_DIM = 128 # @param {type:\"integer\"}\n",
    "DROPOUT = 0.1 # @param {type:\"number\"}\n",
    "PREDICTION_TARGET = \"noise\"\n",
    "USE_CROSS_LEVEL_ATTENTION = True # @param {type:\"boolean\"}\n",
    "\n",
    "# Training Parameters\n",
    "TOTAL_TRAINING_STEPS = 50000 # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 512 # @param {type:\"integer\"}\n",
    "LEARNING_RATE = 2e-4 # @param {type:\"number\"}\n",
    "WEIGHT_DECAY = 1e-5 # @param {type:\"number\"}\n",
    "WARMUP_STEPS = 500 # @param {type:\"integer\"}\n",
    "ENABLE_GRAD_CLIPPING = False # @param {type:\"boolean\"}\n",
    "\n",
    "# Logging & Checkpointing\n",
    "# Set dynamically to 1% of training progress\n",
    "LOG_INTERVAL = max(1, int(TOTAL_TRAINING_STEPS * 0.01))\n",
    "SAVE_INTERVAL = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "# Wavelet Configuration\n",
    "WAVELET_TYPE = \"db2\" # @param {type:\"string\"}\n",
    "WAVELET_LEVELS = \"auto\"\n",
    "\n",
    "# Paths\n",
    "DRIVE_BASE_PATH = \"/content/drive/MyDrive/personal_drive/trading\"\n",
    "CHECKPOINT_DIR = f\"{DRIVE_BASE_PATH}/checkpoints/{UNIQUE_RUN_NAME}\"\n",
    "REPO_DIR = \"/content/WaveletDiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 2: Imports & Fabric Initialization\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Performance Polishing: Set Matmul Precision for GPUs (Ampere+/L4/A100)\n",
    "if torch.cuda.is_available():\n",
    "    # 'high' uses TensorFloat-32 (TF32) for significantly faster matmuls on L4/A100\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# 2. Conditional Dependency Installation\n",
    "deps = [\"lightning\", \"pywavelets\", \"scipy\", \"pandas\", \"tqdm\"]\n",
    "\n",
    "# STRICT CHECK: Only install torch_xla if explicitly on a TPU environment\n",
    "is_tpu = 'COLAB_TPU_ADDR' in os.environ or 'TPU_NAME' in os.environ\n",
    "if is_tpu and not any(\"torch_xla\" in line for line in subprocess.getoutput(\"pip list\").splitlines()):\n",
    "    deps.append(\"torch_xla[tpu]\")\n",
    "\n",
    "try:\n",
    "    import lightning.fabric\n",
    "except ImportError:\n",
    "    print(f\"Installing dependencies ({', '.join(deps)})...\")\n",
    "    subprocess.run([\"pip\", \"install\"] + deps, check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "import lightning as L\n",
    "from lightning.fabric import Fabric\n",
    "\n",
    "# 3. Dynamic Precision Detection\n",
    "if is_tpu:\n",
    "    PRECISION = \"bf16-true\"\n",
    "elif torch.cuda.is_available():\n",
    "    PRECISION = \"bf16-mixed\"\n",
    "else:\n",
    "    PRECISION = \"32-true\"\n",
    "\n",
    "# 4. Initialize Fabric\n",
    "fabric = Fabric(accelerator=\"auto\", devices=\"auto\", precision=PRECISION)\n",
    "fabric.launch()\n",
    "\n",
    "# 5. Clone Repository\n",
    "REPO_URL = \"https://github.com/GarlicWang/WaveletDiff.git\"\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    if fabric.is_global_zero:\n",
    "        print(f\"Cloning {REPO_URL}...\")\n",
    "        subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True, stdout=subprocess.DEVNULL)\n",
    "    fabric.barrier() # Wait for clone\n",
    "\n",
    "# 6. Add to System Path\n",
    "sys.path.append(os.path.join(REPO_DIR, \"src\"))\n",
    "\n",
    "# 7. Create Checkpoint Directory\n",
    "if fabric.is_global_zero:\n",
    "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"[Rank {fabric.global_rank}] Fabric initialized on device: {fabric.device} with precision: {PRECISION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 3: Data Loading (Fabric Optimized)\n",
    "import pandas as pd\n",
    "from data.loaders import create_sliding_windows\n",
    "from data.module import WaveletTimeSeriesDataModule\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def get_dataloaders():\n",
    "    \"\"\"Setup DataModule and return optimal Fabric DataLoader\"\"\"\n",
    "    stocks_path = os.path.join(REPO_DIR, \"data\", \"stocks\", \"stock_data.csv\")\n",
    "    \n",
    "    if fabric.is_global_zero:\n",
    "        print(f\"Loading data from {stocks_path}...\")\n",
    "        \n",
    "    df = pd.read_csv(stocks_path)\n",
    "    CORE_COLS = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df_filtered = df[CORE_COLS]\n",
    "\n",
    "    # Create windows (Memory intensive, so we do it on CPU)\n",
    "    custom_data_windows, _ = create_sliding_windows(\n",
    "        df_filtered.values,\n",
    "        seq_len=SEQ_LEN,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    full_data_tensor = torch.FloatTensor(custom_data_windows)\n",
    "    \n",
    "    # CONFIG\n",
    "    full_config = {\n",
    "        'dataset': {'name': DATASET_NAME, 'seq_len': SEQ_LEN},\n",
    "        'training': {'batch_size': BATCH_SIZE, 'epochs': 1},\n",
    "        'data': {'data_dir': os.path.join(REPO_DIR, \"data\"), 'normalize_data': False},\n",
    "        'wavelet': {'type': WAVELET_TYPE, 'levels': WAVELET_LEVELS}\n",
    "    }\n",
    "\n",
    "    # Create DataModule (Handles Wavelet Transforms internally during init if needed, or we use it for metadata)\n",
    "    datamodule = WaveletTimeSeriesDataModule(config=full_config, data_tensor=full_data_tensor)\n",
    "    \n",
    "    # XLA/GPU OPTIMIZATION: Cast to target dtype BEFORE creating dataset to avoid cast overhead in loop\n",
    "    # If using bf16 precision ON TPU, we cast input data to bf16.\n",
    "    # For GPU (bf16-mixed), we keep as float32 to satisfy AMP requirements.\n",
    "    if PRECISION == \"bf16-true\" and fabric.device.type != \"cpu\":\n",
    "        if fabric.is_global_zero: print(f\"Optimizing: Casting data to bfloat16 for {fabric.device.type}...\")\n",
    "        full_data_tensor = full_data_tensor.to(torch.bfloat16)\n",
    "\n",
    "    dataset = TensorDataset(full_data_tensor)\n",
    "    \n",
    "    # DataLoader\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True, # Important for XLA compilation stability\n",
    "        num_workers=0,  # 0 is often safer for simple TensorDatasets to avoid fork overhead\n",
    "        pin_memory=False \n",
    "    )\n",
    "    \n",
    "    # Fabric Setup (Handles Sharding/Distributed Sampler)\n",
    "    loader = fabric.setup_dataloaders(loader)\n",
    "    \n",
    "    return loader, datamodule, full_config\n",
    "\n",
    "train_loader, datamodule, model_base_config = get_dataloaders()\n",
    "WAVELET_INFO = datamodule.get_wavelet_info()\n",
    "INPUT_DIM = datamodule.get_input_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a025d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 4: Model Initialization\n",
    "from models.transformer import WaveletDiffusionTransformer\n",
    "\n",
    "# Update Config\n",
    "model_base_config.update({\n",
    "    'model': {\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'time_embed_dim': TIME_EMBED_DIM,\n",
    "        'dropout': DROPOUT,\n",
    "        'prediction_target': PREDICTION_TARGET\n",
    "    },\n",
    "    'attention': {'use_cross_level_attention': USE_CROSS_LEVEL_ATTENTION},\n",
    "    'noise': {'schedule': \"exponential\"},\n",
    "    'sampling': {'ddim_eta': 0.0, 'ddim_steps': None},\n",
    "    'energy': {'weight': 0.0},\n",
    "    'optimizer': {\n",
    "        'scheduler_type': 'onecycle',\n",
    "        'lr': LEARNING_RATE,\n",
    "        'warmup_epochs': 5,\n",
    "        'cosine_eta_min': 1e-6\n",
    "    }\n",
    "})\n",
    "\n",
    "def init_system():\n",
    "    model = WaveletDiffusionTransformer(data_module=datamodule, config=model_base_config)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # Fabric Setup\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "    return model, optimizer\n",
    "\n",
    "model, optimizer = init_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 5: Native Fabric Training Loop\n",
    "\n",
    "def train_loop():\n",
    "    # MATCHING SOURCE REPO: OneCycleLR with peak LR at 5x base (1e-3) and pct_start at 0.3 for stocks\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=LEARNING_RATE * 5, \n",
    "        total_steps=TOTAL_TRAINING_STEPS, \n",
    "        pct_start=0.3\n",
    "    )\n",
    "\n",
    "    # Iterator for infinite steps\n",
    "    train_iter = iter(train_loader)\n",
    "    \n",
    "    # Progress bar ONLY on rank 0\n",
    "    if fabric.is_global_zero:\n",
    "        pbar = tqdm(range(TOTAL_TRAINING_STEPS), desc=f\"{fabric.device.type.upper()} Training\")\n",
    "    else:\n",
    "        pbar = range(TOTAL_TRAINING_STEPS)\n",
    "\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "\n",
    "    for step in pbar:\n",
    "        # 1. Fetch Batch\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:\n",
    "            train_iter = iter(train_loader)\n",
    "            batch = next(train_iter)\n",
    "        \n",
    "        x_0 = batch[0]\n",
    "\n",
    "        # 2. Forward & Loss\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Sample time steps\n",
    "        t = torch.randint(0, model.T, (x_0.size(0),), device=fabric.device)\n",
    "        \n",
    "        loss = model.compute_loss(x_0, t)\n",
    "        \n",
    "        # 3. Backward\n",
    "        fabric.backward(loss)\n",
    "        \n",
    "        # 4. Optional Clip Gradients (SLOW on TPU if done every step)\n",
    "        if ENABLE_GRAD_CLIPPING:\n",
    "            fabric.clip_gradients(model, optimizer, max_norm=1.0)\n",
    "            \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # 5. Logging (Async-friendly)\n",
    "        # Happens every 1% of progress to keep training history readable\n",
    "        if (step + 1) % LOG_INTERVAL == 0:\n",
    "            # This forces a sync. \n",
    "            loss_val = loss.item()\n",
    "            \n",
    "            if fabric.is_global_zero:\n",
    "                elapsed = time.time() - t0\n",
    "                steps_per_sec = LOG_INTERVAL / elapsed\n",
    "                t0 = time.time()\n",
    "                \n",
    "                # PERSISTENT LOGGING: Actually print the values to keep history\n",
    "                pct = ((step + 1) / TOTAL_TRAINING_STEPS) * 100\n",
    "                fabric.print(f\"[Step {step+1:5d} | {pct:3.0f}%] loss: {loss_val:.4f} | spd: {steps_per_sec:.2f} it/s\")\n",
    "                pbar.set_postfix({\"loss\": f\"{loss_val:.4f}\", \"spd\": f\"{steps_per_sec:.2f}it/s\"})\n",
    "\n",
    "        # 6. Checkpointing\n",
    "        if (step + 1) % SAVE_INTERVAL == 0:\n",
    "            save_path = os.path.join(CHECKPOINT_DIR, f\"step_{step+1}.ckpt\")\n",
    "            state = {\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "            fabric.save(save_path, state)\n",
    "            if fabric.is_global_zero:\n",
    "                print(f\"\\nSaved checkpoint to {save_path}\")\n",
    "\n",
    "    print(\"Training Finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cell 6: Brief Evaluation (Sanity Check)\n",
    "\n",
    "def sanity_check_sampling():\n",
    "    # Generate a few samples to ensure model learned something\n",
    "    model.eval()\n",
    "    num_samples = 2\n",
    "    print(\"Generating sanity check samples...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Start from random noise in wavelet domain\n",
    "        shape = (num_samples, INPUT_DIM, WAVELET_INFO['n_features'])\n",
    "        samples_wavelet = torch.randn(shape, device=fabric.device, dtype=torch.bfloat16)\n",
    "        \n",
    "        # Reverse diffusion\n",
    "        for i in tqdm(reversed(range(model.T)), total=model.T, desc=\"Sampling\", disable=not fabric.is_global_zero):\n",
    "            t = torch.full((num_samples,), i, device=fabric.device, dtype=torch.long)\n",
    "            t_norm = t.float() / model.T\n",
    "            \n",
    "            eps_theta = model(samples_wavelet, t_norm)\n",
    "            \n",
    "            # Standard DDPM update (simplified)\n",
    "            alpha_t = model.alpha_all[t].view(-1, 1, 1)\n",
    "            alpha_bar_t = model.alpha_bar_all[t].view(-1, 1, 1)\n",
    "            beta_t = model.beta_all[t].view(-1, 1, 1)\n",
    "            \n",
    "            mean = (1 / torch.sqrt(alpha_t)) * (\n",
    "                samples_wavelet - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * eps_theta\n",
    "            )\n",
    "            \n",
    "            if i > 0:\n",
    "                noise = torch.randn_like(samples_wavelet)\n",
    "                samples_wavelet = mean + torch.sqrt(beta_t) * noise\n",
    "            else:\n",
    "                samples_wavelet = mean\n",
    "\n",
    "    print(\"Sampling complete. Converting to time series...\")\n",
    "    # Convert back to time series (ensure cpu float32 for reconstruction stability)\n",
    "    samples_wavelet_cpu = samples_wavelet.float().cpu()\n",
    "    samples_ts = datamodule.convert_wavelet_to_timeseries(samples_wavelet_cpu)\n",
    "    print(f\"Generated samples shape: {samples_ts.shape}\")\n",
    "    return samples_ts\n",
    "\n",
    "if fabric.is_global_zero:\n",
    "    samples = sanity_check_sampling()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
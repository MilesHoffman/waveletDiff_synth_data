{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# WaveletDiff Optuna Hyperparameter Optimization\n",
                "\n",
                "**Clean Interface**: All logic is in `src/torch_gpu_waveletDiff/optuna_config/runner.py`  \n",
                "**Workflow**: Configure ‚Üí Setup ‚Üí Create Study ‚Üí Optimize ‚Üí Analyze ‚Üí Export\n",
                "\n",
                "Modern Features:\n",
                "- üéØ Multi-objective optimization (loss, speed, stability)\n",
                "- üß† TPESampler for intelligent search\n",
                "- ‚úÇÔ∏è HyperbandPruner for early stopping\n",
                "- üíæ Persistent SQLite storage (survives Colab restarts)\n",
                "- üìä Optuna Dashboard for visualization\n",
                "- üîÑ Git-pullable updates (no notebook rewrites needed!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üìã Cell 1: Configuration\n",
                "\n",
                "# === STUDY SETTINGS ===\n",
                "STUDY_NAME = \"waveletdiff_multiobjective_v1\"  # @param {type:\"string\"}\n",
                "N_TRIALS = 50  # @param {type:\"integer\"}\n",
                "TIMEOUT_HOURS = None  # @param {type:\"number\"}\n",
                "\n",
                "# === TRIAL SETTINGS ===\n",
                "STEPS_PER_TRIAL = 2000  # @param {type:\"integer\"}\n",
                "EVAL_INTERVAL = 100  # @param {type:\"integer\"}\n",
                "COMPILE_MODE = None  # @param [\"default\", \"reduce-overhead\", \"max-autotune\", \"None\"]\n",
                "# ^ None = No compilation (faster for short trials)\n",
                "\n",
                "# === OPTIMIZATION MODE ===\n",
                "USE_MULTI_OBJECTIVE = True  # @param {type:\"boolean\"}\n",
                "# ^ If False, uses weighted scalarization (single objective)\n",
                "\n",
                "# Multi-Objective Weights (only used if USE_MULTI_OBJECTIVE=False)\n",
                "WEIGHT_LOSS = 1.0  # @param {type:\"number\"}\n",
                "WEIGHT_SPEED = 0.0  # @param {type:\"number\"}\n",
                "WEIGHT_STABILITY = 0.1  # @param {type:\"number\"}\n",
                "\n",
                "# === PRUNER SETTINGS ===\n",
                "ENABLE_PRUNING = True  # @param {type:\"boolean\"}\n",
                "PRUNER_TYPE = \"hyperband\"  # @param [\"hyperband\", \"median\", \"none\"]\n",
                "PRUNER_MIN_RESOURCE = 500  # @param {type:\"integer\"}\n",
                "PRUNER_REDUCTION_FACTOR = 3  # @param {type:\"integer\"}\n",
                "\n",
                "# === SAMPLER SETTINGS ===\n",
                "SAMPLER_TYPE = \"tpe\"  # @param [\"tpe\", \"random\"]\n",
                "N_STARTUP_TRIALS = 10  # @param {type:\"integer\"}\n",
                "\n",
                "# === DASHBOARD ===\n",
                "ENABLE_DASHBOARD = True  # @param {type:\"boolean\"}\n",
                "DASHBOARD_PORT = 8080  # @param {type:\"integer\"}\n",
                "NGROK_AUTH_TOKEN = \"\"  # @param {type:\"string\"}\n",
                "# ^ Get token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
                "\n",
                "# === HYPERPARAMETER TUNING TOGGLES ===\n",
                "TUNE_LEARNING_RATE = True  # @param {type:\"boolean\"}\n",
                "TUNE_MAX_LR = True  # @param {type:\"boolean\"}\n",
                "TUNE_WEIGHT_DECAY = True  # @param {type:\"boolean\"}\n",
                "TUNE_EMBED_DIM = True  # @param {type:\"boolean\"}\n",
                "TUNE_NUM_HEADS = False  # @param {type:\"boolean\"}\n",
                "TUNE_NUM_LAYERS = True  # @param {type:\"boolean\"}\n",
                "TUNE_DROPOUT = True  # @param {type:\"boolean\"}\n",
                "TUNE_BATCH_SIZE = True  # @param {type:\"boolean\"}\n",
                "TUNE_PCT_START = False  # @param {type:\"boolean\"}\n",
                "TUNE_GRAD_CLIP_NORM = False  # @param {type:\"boolean\"}\n",
                "TUNE_TIME_EMBED_DIM = False  # @param {type:\"boolean\"}\n",
                "\n",
                "# Collect tune flags\n",
                "TUNE_FLAGS = {\n",
                "    'learning_rate': TUNE_LEARNING_RATE,\n",
                "    'max_lr': TUNE_MAX_LR,\n",
                "    'weight_decay': TUNE_WEIGHT_DECAY,\n",
                "    'embed_dim': TUNE_EMBED_DIM,\n",
                "    'num_heads': TUNE_NUM_HEADS,\n",
                "    'num_layers': TUNE_NUM_LAYERS,\n",
                "    'dropout': TUNE_DROPOUT,\n",
                "    'batch_size': TUNE_BATCH_SIZE,\n",
                "    'pct_start': TUNE_PCT_START,\n",
                "    'grad_clip_norm': TUNE_GRAD_CLIP_NORM,\n",
                "    'time_embed_dim': TUNE_TIME_EMBED_DIM,\n",
                "}\n",
                "\n",
                "# === DEFAULT HYPERPARAMETERS ===\n",
                "DEFAULT_HYPERPARAMS = {\n",
                "    'learning_rate': 2e-4,\n",
                "    'max_lr': 1e-3,\n",
                "    'weight_decay': 1e-5,\n",
                "    'embed_dim': 256,\n",
                "    'num_heads': 8,\n",
                "    'num_layers': 8,\n",
                "    'dropout': 0.1,\n",
                "    'batch_size': 512,\n",
                "    'pct_start': 0.3,\n",
                "    'grad_clip_norm': 1.0,\n",
                "    'time_embed_dim': 128,\n",
                "}\n",
                "\n",
                "# === DATASET CONFIGURATION ===\n",
                "DATASET_NAME = \"stocks\"  # @param {type:\"string\"}\n",
                "SEQ_LEN = 24  # @param {type:\"integer\"}\n",
                "WAVELET_TYPE = \"db2\"  # @param {type:\"string\"}\n",
                "WAVELET_LEVELS = \"auto\"\n",
                "DATA_PATH = \"src/copied_waveletDiff/data/stocks/stock_data.csv\"  # @param {type:\"string\"}\n",
                "\n",
                "# === PATHS ===\n",
                "DRIVE_BASE_PATH = \"/content/drive/MyDrive/personal_drive/trading\"  # @param {type:\"string\"}\n",
                "OPTUNA_DB_PATH = f\"{DRIVE_BASE_PATH}/optuna/waveletdiff/optuna_studies/waveletdiff.db\"\n",
                "CHECKPOINT_DIR = f\"{DRIVE_BASE_PATH}/optuna/waveletdiff/optuna_checkpoints/temp\"\n",
                "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
                "REPO_DIR = \"/content/waveletDiff_synth_data\"\n",
                "\n",
                "# Print summary\n",
                "print(\"=\"*60)\n",
                "print(\"CONFIGURATION SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "tuned_params = [k for k, v in TUNE_FLAGS.items() if v]\n",
                "fixed_params = [k for k, v in TUNE_FLAGS.items() if not v]\n",
                "print(f\"Tuning {len(tuned_params)} parameters: {', '.join(tuned_params)}\")\n",
                "print(f\"Fixed {len(fixed_params)} parameters\")\n",
                "print(f\"Mode: {'Multi-Objective' if USE_MULTI_OBJECTIVE else 'Single-Objective'}\")\n",
                "print(f\"Trials: {N_TRIALS} √ó {STEPS_PER_TRIAL} steps\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üîß Cell 2: Environment Setup\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "import importlib\n",
                "\n",
                "print(\"üöÄ Starting bootstrap setup...\")\n",
                "\n",
                "# 1. Bootstrap Repository\n",
                "if not os.path.exists(REPO_DIR):\n",
                "    print(f\"Cloning {REPO_URL} into {REPO_DIR}...\")\n",
                "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
                "else:\n",
                "    print(f\"Repo exists at {REPO_DIR}, pulling latest changes...\")\n",
                "    subprocess.run([\"git\", \"-C\", REPO_DIR, \"pull\"], check=True)\n",
                "\n",
                "# 2. Add repo to path FIRST setup\n",
                "if REPO_DIR not in sys.path:\n",
                "    sys.path.insert(0, REPO_DIR)\n",
                "\n",
                "# 3. Import runner and finish environment setup (mounts drive, installs deps)\n",
                "try:\n",
                "    from src.torch_gpu_waveletDiff.optuna_config import runner\n",
                "    status = runner.setup_environment(\n",
                "        repo_url=REPO_URL,\n",
                "        repo_dir=REPO_DIR,\n",
                "        drive_base_path=DRIVE_BASE_PATH,\n",
                "        optuna_db_path=OPTUNA_DB_PATH,\n",
                "        checkpoint_dir=CHECKPOINT_DIR\n",
                "    )\n",
                "    print(\"‚úÖ Setup complete!\")\n",
                "except ImportError as e:\n",
                "    print(f\"‚ùå Critical error during bootstrap: {e}\")\n",
                "    print(\"Consider restarting the runtime if you just installed new packages.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "init_fabric",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title ‚ö° Cell 3: Initialize Fabric & Config\n",
                "import importlib\n",
                "import sys\n",
                "\n",
                "# Ensure caches are invalidated so it sees the newly installed 'lightning'\n",
                "importlib.invalidate_caches()\n",
                "\n",
                "try:\n",
                "    import lightning\n",
                "except ImportError:\n",
                "    print(\"‚ö†Ô∏è 'lightning' still not found. Attempting a final force install...\")\n",
                "    import subprocess\n",
                "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"lightning\"], check=True)\n",
                "    importlib.invalidate_caches()\n",
                "\n",
                "from src.torch_gpu_waveletDiff.train import trainer\n",
                "fabric = trainer.setup_fabric(precision=\"bf16-mixed\", matmul_precision=\"high\")\n",
                "\n",
                "BASE_CONFIG = {\n",
                "    'dataset': {'name': DATASET_NAME, 'seq_len': SEQ_LEN},\n",
                "    'training': {'batch_size': DEFAULT_HYPERPARAMS['batch_size'], 'epochs': 1},\n",
                "    'data': {'data_dir': f'src/copied_waveletDiff/data/{DATASET_NAME}', 'normalize_data': False},\n",
                "    'wavelet': {'type': WAVELET_TYPE, 'levels': WAVELET_LEVELS},\n",
                "    'model': {'prediction_target': 'noise'},\n",
                "    'attention': {'use_cross_level_attention': True},\n",
                "    'noise': {'schedule': 'exponential'},\n",
                "    'sampling': {'ddim_eta': 0.0, 'ddim_steps': None},\n",
                "    'energy': {'weight': 0.0},\n",
                "    'optimizer': {'scheduler_type': 'onecycle'}\n",
                "}\n",
                "\n",
                "print(f\"‚úÖ Fabric: {fabric.device} | Precision: bf16-mixed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create_study",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üìä Cell 4: Create Optuna Study\n",
                "storage_url = f\"sqlite:///{OPTUNA_DB_PATH}\"\n",
                "\n",
                "study = runner.create_study(\n",
                "    study_name=STUDY_NAME,\n",
                "    storage_url=storage_url,\n",
                "    sampler_type=SAMPLER_TYPE,\n",
                "    n_startup_trials=N_STARTUP_TRIALS,\n",
                "    pruner_type=PRUNER_TYPE,\n",
                "    pruner_min_resource=PRUNER_MIN_RESOURCE,\n",
                "    pruner_reduction_factor=PRUNER_REDUCTION_FACTOR,\n",
                "    enable_pruning=ENABLE_PRUNING,\n",
                "    use_multi_objective=USE_MULTI_OBJECTIVE,\n",
                "    weight_config={'loss': WEIGHT_LOSS, 'speed': WEIGHT_SPEED, 'stability': WEIGHT_STABILITY}\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "optimize",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üöÄ Cell 5: Run Optimization\n",
                "summary = runner.run_optimization(\n",
                "    study=study,\n",
                "    fabric=fabric,\n",
                "    base_config=BASE_CONFIG,\n",
                "    repo_dir=REPO_DIR,\n",
                "    data_path=DATA_PATH,\n",
                "    tune_flags=TUNE_FLAGS,\n",
                "    default_hyperparams=DEFAULT_HYPERPARAMS,\n",
                "    checkpoint_dir=CHECKPOINT_DIR,\n",
                "    trial_steps=STEPS_PER_TRIAL,\n",
                "    eval_interval=EVAL_INTERVAL,\n",
                "    compile_mode=COMPILE_MODE,\n",
                "    n_trials=N_TRIALS,\n",
                "    timeout_hours=TIMEOUT_HOURS,\n",
                "    use_multi_objective=USE_MULTI_OBJECTIVE,\n",
                "    enable_dashboard=ENABLE_DASHBOARD,\n",
                "    dashboard_port=DASHBOARD_PORT,\n",
                "    ngrok_token=NGROK_AUTH_TOKEN,\n",
                "    storage_url=storage_url\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analyze",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üìà Cell 6: Analyze Results\n",
                "analysis = runner.analyze_results(\n",
                "    study_name=STUDY_NAME,\n",
                "    storage_url=storage_url,\n",
                "    use_multi_objective=USE_MULTI_OBJECTIVE\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "export",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title üíæ Cell 7: Export Best Configs\n",
                "exported_files = runner.export_best_configs(\n",
                "    study_name=STUDY_NAME,\n",
                "    storage_url=storage_url,\n",
                "    checkpoint_dir=CHECKPOINT_DIR,\n",
                "    use_multi_objective=USE_MULTI_OBJECTIVE\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "639c738b",
            "metadata": {},
            "source": [
                "# WaveletDiff Training (Stocks Dataset)\n",
                "\n",
                "This notebook trains the WaveletDiff model on the **stocks** dataset using the modular `src` directory.\n",
                "\n",
                "### Workflow:\n",
                "1. **Configuration**: Tune hyperparameters, paths, and precision.\n",
                "2. **Setup**: Clones the repo, installs dependencies.\n",
                "3. **Environment**: Configures PyTorch precision and seeds.\n",
                "4. **Data**: Load and prepare data.\n",
                "5. **Model**: Initialize the model.\n",
                "6. **Train**: Run training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5be5e355",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 1: Global Configuration\n",
                "import random\n",
                "\n",
                "# --- Experiment Identity ---\n",
                "RUN_NAME = \"stocks_baseline_v1\" # @param {type:\"string\"}\n",
                "RUN_ID = f\"{random.randint(0, 999):03d}\"\n",
                "UNIQUE_RUN_NAME = f\"{RUN_NAME}_{RUN_ID}\"\n",
                "\n",
                "# --- Dataset (Stocks-specific, fixed) ---\n",
                "DATASET_NAME = \"stocks\"\n",
                "SEQ_LEN = 24\n",
                "NORMALIZE_DATA = True\n",
                "\n",
                "# --- Model Hyperparameters ---\n",
                "EMBED_DIM = 256 # @param {type:\"integer\"}\n",
                "NUM_HEADS = 8 # @param {type:\"integer\"}\n",
                "NUM_LAYERS = 8 # @param {type:\"integer\"}\n",
                "TIME_EMBED_DIM = 128 # @param {type:\"integer\"}\n",
                "DROPOUT = 0.1 # @param {type:\"number\"}\n",
                "\n",
                "# --- Training Hyperparameters ---\n",
                "NUM_EPOCHS = 5000 # @param {type:\"integer\"}\n",
                "BATCH_SIZE = 512 # @param {type:\"integer\"}\n",
                "LEARNING_RATE = 2e-4 # @param {type:\"number\"}\n",
                "GRADIENT_CLIP_VAL = 1.0 # @param {type:\"number\"}\n",
                "\n",
                "# --- Optimizer Hyperparameters ---\n",
                "WEIGHT_DECAY = 1e-5 # @param {type:\"number\"}\n",
                "ONECYCLE_MAX_LR = 1e-3 # @param {type:\"number\"}\n",
                "ONECYCLE_PCT_START = 0.3 # @param {type:\"number\"}\n",
                "\n",
                "# --- Logging & Checkpointing ---\n",
                "LOG_EVERY_N_STEPS = 50 # @param {type:\"integer\"}\n",
                "SAVE_EVERY_N_EPOCHS = 100 # @param {type:\"integer\"}\n",
                "\n",
                "# --- Hardware & Precision ---\n",
                "PRECISION = \"bf16-mixed\" # @param [\"32\", \"bf16-mixed\"]\n",
                "MATMUL_PRECISION = \"medium\" # @param [\"medium\", \"high\"]\n",
                "\n",
                "# --- Paths ---\n",
                "DRIVE_BASE_PATH = \"/content/drive/MyDrive/personal_drive/trading\" # @param {type:\"string\"}\n",
                "OUTPUT_DIR = f\"{DRIVE_BASE_PATH}/checkpoints/temp/{UNIQUE_RUN_NAME}\"\n",
                "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
                "REPO_DIR = \"/content/waveletDiff_synth_data\"\n",
                "\n",
                "# --- Reproducibility ---\n",
                "SEED = 42 # @param {type:\"integer\"}\n",
                "\n",
                "# --- Fixed Settings (Stocks configuration) ---\n",
                "PREDICTION_TARGET = \"noise\"\n",
                "USE_CROSS_LEVEL_ATTENTION = True\n",
                "ENERGY_WEIGHT = 0.0\n",
                "NOISE_SCHEDULE = \"exponential\"\n",
                "SCHEDULER_TYPE = \"onecycle\"\n",
                "WAVELET_TYPE = \"db2\"\n",
                "WAVELET_LEVELS = \"auto\"\n",
                "DDIM_ETA = 0.0\n",
                "DDIM_STEPS = None\n",
                "ACCELERATOR = \"gpu\"\n",
                "DEVICES = 1\n",
                "SAVE_TOP_K = -1\n",
                "WARMUP_EPOCHS = 50"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d31d0907",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 2: Setup (Clone, Install, Mount)\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    if not os.path.exists('/content/drive'):\n",
                "        drive.mount('/content/drive')\n",
                "    print(\"✅ Drive mounted\")\n",
                "except ImportError:\n",
                "    print(\"Not running on Colab. Skipping Drive mount.\")\n",
                "    DRIVE_BASE_PATH = \"local_checkpoints\"\n",
                "    os.makedirs(DRIVE_BASE_PATH, exist_ok=True)\n",
                "\n",
                "if not os.path.exists(REPO_DIR):\n",
                "    print(f\"Cloning {REPO_URL} into {REPO_DIR}...\")\n",
                "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
                "else:\n",
                "    print(f\"Repo exists at {REPO_DIR}, pulling latest changes...\")\n",
                "    subprocess.run([\"git\", \"-C\", REPO_DIR, \"pull\"], check=True)\n",
                "\n",
                "if REPO_DIR not in sys.path:\n",
                "    sys.path.insert(0, REPO_DIR)\n",
                "\n",
                "print(\"Installing dependencies...\")\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pytorch-lightning\", \"pywavelets\", \"scipy\", \"pandas\", \"tqdm\", \"lightning\"], check=True)\n",
                "print(\"✅ Dependencies installed\")\n",
                "\n",
                "import importlib\n",
                "importlib.invalidate_caches()\n",
                "print(\"✅ Env Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4169bed8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 3: Setup Environment\n",
                "import torch\n",
                "import pytorch_lightning as pl\n",
                "\n",
                "if SEED is not None:\n",
                "    pl.seed_everything(SEED)\n",
                "\n",
                "try:\n",
                "    torch.set_float32_matmul_precision(MATMUL_PRECISION)\n",
                "    print(f\"✅ Matmul precision set to {MATMUL_PRECISION}\")\n",
                "except Exception as e:\n",
                "    print(f\"Could not set matmul precision: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0296d61c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 4: Load Data\n",
                "from src.data import WaveletTimeSeriesDataModule\n",
                "import numpy as np\n",
                "\n",
                "config = {\n",
                "    'training': {'epochs': NUM_EPOCHS, 'batch_size': BATCH_SIZE, 'save_model': True},\n",
                "    'dataset': {'name': DATASET_NAME, 'seq_len': SEQ_LEN},\n",
                "    'data': {'data_dir': REPO_DIR, 'normalize_data': NORMALIZE_DATA},\n",
                "    'wavelet': {'type': WAVELET_TYPE, 'levels': WAVELET_LEVELS},\n",
                "    'model': {\n",
                "        'embed_dim': EMBED_DIM, 'num_heads': NUM_HEADS, 'num_layers': NUM_LAYERS,\n",
                "        'time_embed_dim': TIME_EMBED_DIM, 'dropout': DROPOUT, 'prediction_target': PREDICTION_TARGET,\n",
                "    },\n",
                "    'attention': {'use_cross_level_attention': USE_CROSS_LEVEL_ATTENTION},\n",
                "    'energy': {'weight': ENERGY_WEIGHT},\n",
                "    'noise': {'schedule': NOISE_SCHEDULE},\n",
                "    'optimizer': {\n",
                "        'scheduler_type': SCHEDULER_TYPE, 'warmup_epochs': WARMUP_EPOCHS, 'lr': LEARNING_RATE,\n",
                "        'weight_decay': WEIGHT_DECAY, 'onecycle_max_lr': ONECYCLE_MAX_LR, 'onecycle_pct_start': ONECYCLE_PCT_START,\n",
                "    },\n",
                "    'sampling': {'ddim_eta': DDIM_ETA, 'ddim_steps': DDIM_STEPS},\n",
                "    'paths': {'output_dir': OUTPUT_DIR},\n",
                "}\n",
                "\n",
                "datamodule = WaveletTimeSeriesDataModule(config=config)\n",
                "print(f\"✅ Data loaded: {datamodule.raw_data_tensor.shape}\")\n",
                "print(f\"✅ Wavelet dimension: {datamodule.get_input_dim()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "306e5338",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 5: Initialize Model\n",
                "from src.models import WaveletDiffusionTransformer\n",
                "\n",
                "model = WaveletDiffusionTransformer(data_module=datamodule, config=config)\n",
                "print(\"✅ Model initialized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6924e91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 6: Run Training\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import ModelCheckpoint, Timer, TQDMProgressBar\n",
                "import os\n",
                "\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "callbacks = [\n",
                "    Timer(),\n",
                "    TQDMProgressBar(refresh_rate=1),\n",
                "    ModelCheckpoint(\n",
                "        dirpath=OUTPUT_DIR,\n",
                "        filename='checkpoint-{epoch:02d}',\n",
                "        save_top_k=SAVE_TOP_K,\n",
                "        every_n_epochs=SAVE_EVERY_N_EPOCHS\n",
                "    )\n",
                "]\n",
                "\n",
                "trainer = pl.Trainer(\n",
                "    max_epochs=NUM_EPOCHS,\n",
                "    accelerator=ACCELERATOR,\n",
                "    devices=DEVICES,\n",
                "    precision=PRECISION,\n",
                "    gradient_clip_val=GRADIENT_CLIP_VAL,\n",
                "    gradient_clip_algorithm=\"norm\",\n",
                "    callbacks=callbacks,\n",
                "    enable_checkpointing=True,\n",
                "    logger=False,\n",
                "    log_every_n_steps=LOG_EVERY_N_STEPS\n",
                ")\n",
                "\n",
                "print(\"Starting training...\")\n",
                "trainer.fit(model, datamodule)\n",
                "print(f\"✅ Training finished. Checkpoints saved to {OUTPUT_DIR}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
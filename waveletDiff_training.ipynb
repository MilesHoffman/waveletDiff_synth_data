{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# WaveletDiff Training (Replication)\n",
                "\n",
                "This notebook replicates the logic of `src/train.py` exactly, using a config cell for parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 1: Global Configuration\n",
                "\n",
                "# --- Experiment Identity ---\n",
                "EXPERIMENT_NAME = \"default_experiment\" # @param {type:\"string\"}\n",
                "\n",
                "# --- Dataset ---\n",
                "DATASET_NAME = \"etth1\" # @param {type:\"string\"}\n",
                "SEQ_LEN = 24 # @param {type:\"integer\"}\n",
                "NORMALIZE_DATA = True # @param {type:\"boolean\"}\n",
                "\n",
                "# --- Model Hyperparameters ---\n",
                "EMBED_DIM = 256 # @param {type:\"integer\"}\n",
                "NUM_HEADS = 8 # @param {type:\"integer\"}\n",
                "NUM_LAYERS = 8 # @param {type:\"integer\"}\n",
                "TIME_EMBED_DIM = 128 # @param {type:\"integer\"}\n",
                "DROPOUT = 0.1 # @param {type:\"number\"}\n",
                "PREDICTION_TARGET = \"noise\" # @param [\"noise\", \"coefficient\"]\n",
                "\n",
                "# --- Attention & Energy ---\n",
                "USE_CROSS_LEVEL_ATTENTION = True # @param {type:\"boolean\"}\n",
                "ENERGY_WEIGHT = 0.0 # @param {type:\"number\"}\n",
                "\n",
                "# --- Noise Schedule ---\n",
                "NOISE_SCHEDULE = \"exponential\" # @param [\"exponential\", \"cosine\", \"linear\"]\n",
                "\n",
                "# --- Wavelet ---\n",
                "WAVELET_TYPE = \"auto\" # @param {type:\"string\"}\n",
                "WAVELET_LEVELS = \"auto\" # @param {type:\"raw\"}\n",
                "\n",
                "# --- Sampling ---\n",
                "SAMPLING_METHOD = \"ddpm\" # @param [\"ddpm\", \"ddim\"]\n",
                "DDIM_ETA = 0.0 # @param {type:\"number\"}\n",
                "DDIM_STEPS = None # @param {type:\"raw\"}\n",
                "\n",
                "# --- Optimizer ---\n",
                "SCHEDULER_TYPE = \"onecycle\" # @param [\"onecycle\", \"cosine_warmup\", \"plateau_warmup\", \"cosine\", \"plateau\"]\n",
                "WARMUP_EPOCHS = 50 # @param {type:\"integer\"}\n",
                "LEARNING_RATE = 0.0002 # @param {type:\"number\"}\n",
                "\n",
                "# --- Training ---\n",
                "NUM_EPOCHS = 5000 # @param {type:\"integer\"}\n",
                "BATCH_SIZE = 512 # @param {type:\"integer\"}\n",
                "SAVE_MODEL = True # @param {type:\"boolean\"}\n",
                "\n",
                "# --- Paths ---\n",
                "DATA_DIR = \"../data\" # @param {type:\"string\"}\n",
                "OUTPUT_DIR = \"../outputs\" # @param {type:\"string\"}\n",
                "\n",
                "# --- Reproducibility ---\n",
                "SEED = 42 # @param {type:\"integer\"}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 2: Setup\n",
                "import os\n",
                "import sys\n",
                "import argparse\n",
                "import time\n",
                "from datetime import timedelta\n",
                "from pathlib import Path\n",
                "import random\n",
                "\n",
                "import torch\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import Timer\n",
                "import numpy as np\n",
                "\n",
                "# Add source to path if running from root or adjacent\n",
                "# We need 'WaveletDiff_source/src' to be in sys.path so 'import models' works\n",
                "project_root = os.getcwd()\n",
                "src_path = os.path.join(project_root, 'WaveletDiff_source', 'src')\n",
                "\n",
                "if src_path not in sys.path:\n",
                "    sys.path.append(src_path)\n",
                "    print(f\"Added {src_path} to sys.path\")\n",
                "\n",
                "try:\n",
                "    from models import WaveletDiffusionTransformer\n",
                "    from training import DiffusionTrainer\n",
                "    from data import WaveletTimeSeriesDataModule\n",
                "    from utils import ConfigManager\n",
                "    print(\"✅ Imports successful\")\n",
                "except ImportError as e:\n",
                "    print(f\"❌ Import failed: {e}\")\n",
                "    print(\"Please ensure WaveletDiff_source/src exists.\")\n",
                "\n",
                "# Set Precision\n",
                "try:\n",
                "    torch.set_float32_matmul_precision('medium')\n",
                "    print(\"Enabled optimized matmul precision\")\n",
                "except Exception as e:\n",
                "    print(f\"Could not set matmul precision: {e}\")\n",
                "    print(\"Continuing with default precision...\")\n",
                "\n",
                "# Seed\n",
                "pl.seed_everything(SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 3: Configuration Processing\n",
                "\n",
                "# Handle WAVELET_LEVELS type\n",
                "wavelet_levels = str(WAVELET_LEVELS)\n",
                "if wavelet_levels.isdigit():\n",
                "    wavelet_levels = int(wavelet_levels)\n",
                "elif wavelet_levels.lower() == \"auto\":\n",
                "    wavelet_levels = \"auto\"\n",
                "\n",
                "config = {\n",
                "    'training': {\n",
                "        'epochs': NUM_EPOCHS,\n",
                "        'batch_size': BATCH_SIZE,\n",
                "        'save_model': SAVE_MODEL\n",
                "    },\n",
                "    'model': {\n",
                "        'embed_dim': EMBED_DIM,\n",
                "        'num_heads': NUM_HEADS,\n",
                "        'num_layers': NUM_LAYERS,\n",
                "        'time_embed_dim': TIME_EMBED_DIM,\n",
                "        'dropout': DROPOUT,\n",
                "        'prediction_target': PREDICTION_TARGET\n",
                "    },\n",
                "    'attention': {\n",
                "        'use_cross_level_attention': USE_CROSS_LEVEL_ATTENTION\n",
                "    },\n",
                "    'energy': {\n",
                "        'weight': ENERGY_WEIGHT\n",
                "    },\n",
                "    'noise': {\n",
                "        'schedule': NOISE_SCHEDULE\n",
                "    },\n",
                "    'wavelet': {\n",
                "        'type': WAVELET_TYPE,\n",
                "        'levels': wavelet_levels\n",
                "    },\n",
                "    'sampling': {\n",
                "        'method': SAMPLING_METHOD,\n",
                "        'ddim_eta': DDIM_ETA,\n",
                "        'ddim_steps': DDIM_STEPS\n",
                "    },\n",
                "    'data': {\n",
                "        'normalize_data': NORMALIZE_DATA,\n",
                "        'data_dir': DATA_DIR\n",
                "    },\n",
                "    'optimizer': {\n",
                "        'scheduler_type': SCHEDULER_TYPE,\n",
                "        'warmup_epochs': WARMUP_EPOCHS,\n",
                "        'lr': LEARNING_RATE\n",
                "    },\n",
                "    'dataset': {\n",
                "        'name': DATASET_NAME,\n",
                "        'seq_len': SEQ_LEN\n",
                "    },\n",
                "    'evaluation': {\n",
                "        'num_samples': 20000\n",
                "    },\n",
                "    'paths': {\n",
                "        'output_dir': OUTPUT_DIR\n",
                "    }\n",
                "}\n",
                "\n",
                "print(f\"Starting WaveletDiff Training\")\n",
                "print(f\"Dataset: {config['dataset']['name']}\")\n",
                "print(f\"Sequence Length: {config['dataset']['seq_len']}\")\n",
                "print(f\"Epochs: {config['training']['epochs']}\")\n",
                "print(f\"Batch Size: {config['training']['batch_size']}\")\n",
                "print(f\"Prediction Target: {config['model']['prediction_target']}\")\n",
                "print(f\"Cross-level Attention: {'Enabled' if config['attention']['use_cross_level_attention'] else 'Disabled'} (cross_only)\")\n",
                "print(f\"Loss Strategy: coefficient_weighted (approximation_weight=2)\")\n",
                "print(f\"Energy Term: {'Enabled' if config['energy']['weight'] > 0 else 'Disabled'} (level_feature, absolute)\")\n",
                "print(f\"Noise Schedule: {config['noise']['schedule']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 4: Data Module Setup\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"SETTING UP DATA MODULE\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "data_module = WaveletTimeSeriesDataModule(config=config)\n",
                "\n",
                "print(f\"Data module setup complete\")\n",
                "print(f\"Input dimension: {data_module.get_input_dim()}\")\n",
                "print(f\"Dataset size: {len(data_module.dataset)}\")\n",
                "print(f\"Wavelet: {data_module.wavelet_type} with {data_module.wavelet_info['levels']} levels\")\n",
                "\n",
                "# Get wavelet info\n",
                "wavelet_info = data_module.get_wavelet_info()\n",
                "print(f\"   Wavelet levels: {wavelet_info['levels']}\")\n",
                "for i, shape in enumerate(wavelet_info['coeffs_shapes']):\n",
                "    print(f\"     Level {i}: {shape} -> {np.prod(shape)} coefficients\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 5: Model Initialization\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"INITIALIZING MODEL\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "model = WaveletDiffusionTransformer(data_module=data_module, config=config)\n",
                "\n",
                "# Create experiment directories\n",
                "dataset_name = config['dataset']['name']\n",
                "\n",
                "# Create experiment folder structure\n",
                "experiment_name = EXPERIMENT_NAME\n",
                "experiment_dir = Path(config['paths']['output_dir']) / experiment_name\n",
                "experiment_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "model_filename = f\"checkpoint.ckpt\"\n",
                "model_path = experiment_dir / model_filename\n",
                "\n",
                "print(f\"Experiment: {experiment_name}\")\n",
                "print(f\"Model checkpoint will be saved to: {model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 6: Training\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TRAINING MODEL\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "trainer = pl.Trainer(\n",
                "    max_epochs=config['training']['epochs'],\n",
                "    accelerator='gpu',\n",
                "    devices='auto',\n",
                "    strategy=\"ddp_find_unused_parameters_true\",\n",
                "    precision=\"32\",\n",
                "    callbacks=[Timer()],\n",
                "    enable_checkpointing=False,\n",
                "    enable_progress_bar=False,\n",
                "    log_every_n_steps=50,\n",
                "    gradient_clip_val=1.0,\n",
                "    detect_anomaly=False,\n",
                "    gradient_clip_algorithm=\"norm\",\n",
                "    logger=False\n",
                ")\n",
                "\n",
                "start_time = time.time()\n",
                "trainer.fit(model, data_module)\n",
                "training_time = time.time() - start_time\n",
                "\n",
                "print(f\"Training completed in {timedelta(seconds=training_time)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 7: Save Model\n",
                "\n",
                "if config['training']['save_model']:\n",
                "    trainer.save_checkpoint(str(model_path))\n",
                "    print(f\"Model saved to {model_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
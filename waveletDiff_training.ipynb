{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "51264d61",
            "metadata": {},
            "source": [
                "# WaveletDiff Training (Enhanced)\n",
                "\n",
                "This notebook provides a robust environment for training the WaveletDiff model, with full control over repository branches, hyperparameters, compilation, and logging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9d48cf25",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 1: Global Configuration\n",
                "\n",
                "# --- Environment ---\n",
                "BRANCH = \"develop\" # @param {type:\"string\"}\n",
                "\n",
                "# --- Data Paths ---\n",
                "DATASET = \"stocks\" # @param [\"stocks\", \"ett\", \"fmri\", \"exchange_rate\", \"eeg\"]\n",
                "EXPERIMENT_NAME = \"stocks_experiment\" # @param {type:\"string\"}\n",
                "# Corrected path: relative to repository root\n",
                "DATA_DIR = \"data/stocks/stock_data.csv\" # @param {type:\"string\"}\n",
                "\n",
                "# --- Core Hyperparameters ---\n",
                "EPOCHS = 5000 # @param {type:\"integer\"}\n",
                "BATCH_SIZE = 512 # @param {type:\"integer\"}\n",
                "SEQ_LEN = 24 # @param {type:\"integer\"}\n",
                "LR = 0.0002 # @param {type:\"number\"}\n",
                "\n",
                "# --- Performance ---\n",
                "PRECISION = \"bf16-mixed\" # @param [\"32\", \"bf16-mixed\", \"16-mixed\"]\n",
                "MATMUL_PRECISION = \"medium\" # @param [\"highest\", \"high\", \"medium\"]\n",
                "\n",
                "# --- Compilation ---\n",
                "COMPILE_ENABLED = True # @param {type:\"boolean\"}\n",
                "COMPILE_MODE = \"reduce-overhead\" # @param [\"default\", \"reduce-overhead\", \"max-autotune\"]\n",
                "COMPILE_FULLGRAPH = False # @param {type:\"boolean\"}\n",
                "\n",
                "# --- Logging & UI ---\n",
                "LOG_EVERY_N_EPOCHS = 10 # @param {type:\"integer\"}\n",
                "ENABLE_PROGRESS_BAR = True # @param {type:\"boolean\"}\n",
                "\n",
                "# --- Profiling ---\n",
                "PROFILE_ENABLED = False # @param {type:\"boolean\"}\n",
                "PROFILE_WAIT_STEPS = 5 # @param {type:\"integer\"}\n",
                "PROFILE_WARMUP_STEPS = 3 # @param {type:\"integer\"}\n",
                "PROFILE_ACTIVE_STEPS = 5 # @param {type:\"integer\"}\n",
                "PROFILE_WAIT_EPOCHS = 0 # @param {type:\"integer\"}\n",
                "\n",
                "# --- Google Drive Persistence ---\n",
                "DRIVE_MOUNT_PATH = \"/content/drive\" # @param {type:\"string\"}\n",
                "DRIVE_BASE_PATH = \"/content/drive/MyDrive/waveletDiff_experiments/checkpoints\" # @param {type:\"string\"}\n",
                "SAVE_TO_DRIVE = True # @param {type:\"boolean\"}\n",
                "SAVE_WEIGHTS_ONLY = True # @param {type:\"boolean\"}\n",
                "\n",
                "# --- Model Architecture ---\n",
                "EMBED_DIM = 256\n",
                "NUM_HEADS = 8 \n",
                "NUM_LAYERS = 8\n",
                "TIME_EMBED_DIM = 128 \n",
                "DROPOUT = 0.1\n",
                "PREDICTION_TARGET = \"noise\"\n",
                "USE_CROSS_LEVEL_ATTENTION = True\n",
                "\n",
                "# --- Wavelet & Noise ---\n",
                "WAVELET_TYPE = \"db2\"\n",
                "WAVELET_LEVELS = \"auto\"\n",
                "NOISE_SCHEDULE = \"exponential\"\n",
                "ENERGY_WEIGHT = 0.0\n",
                "\n",
                "# --- Optimizer ---\n",
                "SCHEDULER_TYPE = \"onecycle\"\n",
                "WARMUP_EPOCHS = 50 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "898a558b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 2: Setup & environment\n",
                "import os\n",
                "import sys\n",
                "import shutil\n",
                "\n",
                "# Fixed base path for Colab - prevents nesting issues\n",
                "COLAB_BASE = \"/content\"\n",
                "REPO_URL = \"https://github.com/MilesHoffman/waveletDiff_synth_data.git\"\n",
                "REPO_NAME = \"waveletDiff_synth_data\"\n",
                "REPO_PATH = os.path.join(COLAB_BASE, REPO_NAME)  # Always /content/waveletDiff_synth_data\n",
                "\n",
                "# Reset to base directory first to avoid nesting\n",
                "%cd {COLAB_BASE}\n",
                "\n",
                "if not os.path.exists(REPO_PATH):\n",
                "    print(f\"Cloning {REPO_URL} branch {BRANCH}...\")\n",
                "    !git clone -b {BRANCH} {REPO_URL} {REPO_NAME}\n",
                "else:\n",
                "    # Check for nested repo and clean up if needed\n",
                "    nested_path = os.path.join(REPO_PATH, REPO_NAME)\n",
                "    if os.path.exists(nested_path):\n",
                "        print(f\"⚠️ Detected nested repository. Cleaning up...\")\n",
                "        shutil.rmtree(REPO_PATH)\n",
                "        print(f\"Cloning fresh {REPO_URL} branch {BRANCH}...\")\n",
                "        !git clone -b {BRANCH} {REPO_URL} {REPO_NAME}\n",
                "    else:\n",
                "        print(f\"Updating {REPO_NAME} to branch {BRANCH}...\")\n",
                "        !git -C {REPO_NAME} fetch --all\n",
                "        !git -C {REPO_NAME} checkout {BRANCH}\n",
                "        !git -C {REPO_NAME} pull origin {BRANCH}\n",
                "\n",
                "# Add repo to path for notebook usage\n",
                "if REPO_PATH not in sys.path:\n",
                "    sys.path.append(REPO_PATH)\n",
                "\n",
                "!pip install -q pytorch-lightning pywavelets scipy pandas tqdm lightning\n",
                "print(f\"✅ Repository ready at: {REPO_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09303e14",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 3: Run WaveletDiff Training\n",
                "%cd {REPO_PATH}\n",
                "\n",
                "# Ensure DATA_DIR is absolute so there is no ambiguity\n",
                "if not os.path.isabs(DATA_DIR):\n",
                "    ABS_DATA_DIR = os.path.join(REPO_PATH, DATA_DIR)\n",
                "else:\n",
                "    ABS_DATA_DIR = DATA_DIR\n",
                "\n",
                "print(f\"Running training for {DATASET}...\")\n",
                "print(f\"Using Data Dir: {ABS_DATA_DIR}\")\n",
                "\n",
                "!python src/train.py \\\n",
                "    --dataset {DATASET} \\\n",
                "    --experiment_name {EXPERIMENT_NAME} \\\n",
                "    --data_dir {ABS_DATA_DIR} \\\n",
                "    --epochs {EPOCHS} \\\n",
                "    --batch_size {BATCH_SIZE} \\\n",
                "    --seq_len {SEQ_LEN} \\\n",
                "    --lr {LR} \\\n",
                "    --precision {PRECISION} \\\n",
                "    --matmul_precision {MATMUL_PRECISION} \\\n",
                "    --compile_enabled {str(COMPILE_ENABLED).lower()} \\\n",
                "    --compile_mode {COMPILE_MODE} \\\n",
                "    --compile_fullgraph {str(COMPILE_FULLGRAPH).lower()} \\\n",
                "    --log_every_n_epochs {LOG_EVERY_N_EPOCHS} \\\n",
                "    --enable_progress_bar {str(ENABLE_PROGRESS_BAR).lower()} \\\n",
                "    --profile_enabled {str(PROFILE_ENABLED).lower()} \\\n",
                "    --profile_wait_steps {PROFILE_WAIT_STEPS} \\\n",
                "    --profile_warmup_steps {PROFILE_WARMUP_STEPS} \\\n",
                "    --profile_active_steps {PROFILE_ACTIVE_STEPS} \\\n",
                "    --profile_wait_epochs {PROFILE_WAIT_EPOCHS} \\\n",
                "    --save_weights_only {str(SAVE_WEIGHTS_ONLY).lower()} \\\n",
                "    --embed_dim {EMBED_DIM} \\\n",
                "    --num_heads {NUM_HEADS} \\\n",
                "    --num_layers {NUM_LAYERS} \\\n",
                "    --time_embed_dim {TIME_EMBED_DIM} \\\n",
                "    --dropout {DROPOUT} \\\n",
                "    --prediction_target {PREDICTION_TARGET} \\\n",
                "    --use_cross_level_attention {str(USE_CROSS_LEVEL_ATTENTION).lower()} \\\n",
                "    --wavelet_type {WAVELET_TYPE} \\\n",
                "    --wavelet_levels {WAVELET_LEVELS} \\\n",
                "    --noise_schedule {NOISE_SCHEDULE} \\\n",
                "    --energy_weight {ENERGY_WEIGHT} \\\n",
                "    --scheduler_type {SCHEDULER_TYPE} \\\n",
                "    --warmup_epochs {WARMUP_EPOCHS}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "drive_save_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# @title Cell 4: Save Experiment to Google Drive\n",
                "from google.colab import drive\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "if SAVE_TO_DRIVE:\n",
                "    # 1. Mount Drive\n",
                "    if not os.path.exists(DRIVE_MOUNT_PATH):\n",
                "        drive.mount(DRIVE_MOUNT_PATH)\n",
                "\n",
                "    # 2. Look for experiment output in possible locations\n",
                "    possible_locations = [\n",
                "        os.path.join(REPO_PATH, \"outputs\", EXPERIMENT_NAME),\n",
                "        os.path.join(\"/content\", \"outputs\", EXPERIMENT_NAME),\n",
                "        os.path.join(os.getcwd(), \"outputs\", EXPERIMENT_NAME)\n",
                "    ]\n",
                "    \n",
                "    experiment_output_dir = None\n",
                "    for loc in possible_locations:\n",
                "        if os.path.exists(loc):\n",
                "            experiment_output_dir = loc\n",
                "            # Also define where to create the archive base name based on found location location\n",
                "            # But we can just create it in /content to be safe\n",
                "            archive_base_name = os.path.join(\"/content\", EXPERIMENT_NAME)\n",
                "            break\n",
                "            \n",
                "    archive_name = f\"{EXPERIMENT_NAME}.tar.gz\"\n",
                "    \n",
                "    # Create destination folder if not exists\n",
                "    os.makedirs(DRIVE_BASE_PATH, exist_ok=True)\n",
                "    destination_path = os.path.join(DRIVE_BASE_PATH, archive_name)\n",
                "\n",
                "    if experiment_output_dir is None:\n",
                "        print(f\"❌ ERROR: Experiment directory not found.\")\n",
                "        print(f\"Checked locations: {possible_locations}\")\n",
                "    else:\n",
                "        print(f\"✅ Found experiment directory at: {experiment_output_dir}\")\n",
                "        print(f\"Contents: {os.listdir(experiment_output_dir)}\")\n",
                "        print(f\"Compressing experiment artifacts...\")\n",
                "        \n",
                "        try:\n",
                "            # Create tar.gz archive from the experiment output directory\n",
                "            archive_path = shutil.make_archive(archive_base_name, 'gztar', experiment_output_dir)\n",
                "            \n",
                "            print(f\"Archive created at: {archive_path}\")\n",
                "            print(f\"Copying to Google Drive: {destination_path}...\")\n",
                "            \n",
                "            shutil.copy2(archive_path, destination_path)\n",
                "            print(f\"✅ Successfully saved experiment archive to Google Drive!\")\n",
                "            print(f\"Location: {destination_path}\")\n",
                "            \n",
                "            # Cleanup local archive\n",
                "            os.remove(archive_path)\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"❌ Error saving to Drive: {e}\")\n",
                "else:\n",
                "    print(\"Skipping Save to Drive (SAVE_TO_DRIVE=False)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}